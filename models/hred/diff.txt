5a6
> 
7c8
< __authors__ = ("Iulian Vlad Serban")
---
> __authors__ = ("Michael Noseworthy, Nicolas Angelard-Gontier, Iulian Vlad Serban")
12a14
> 
16d17
< from theano import scan
18d18
< from theano.tensor.nnet.conv3d2d import *
22,23c22,23
< from model import *
< from utils import *
---
> from model import Model
> from utils import NormalInit, OrthogonalInit, NormalizationOperator, Maxout, Adadelta, Adam, Adagrad, SoftMax, GrabProbs, RMSProp
25c25,26
< import operator
---
> from encdec_base import EncoderDecoderBase
> #from critic_enc import CriticDecoder
32,44d32
< class EncoderDecoderBase():
<     def __init__(self, state, rng, parent):
<         self.rng = rng
<         self.parent = parent
<         
<         self.state = state
<         self.__dict__.update(state)
<         
<         self.dialogue_rec_activation = eval(self.dialogue_rec_activation)
<         self.sent_rec_activation = eval(self.sent_rec_activation)
<          
<         self.params = []
< 
207,208d194
< 
< 
399c385
<             ones_scalar = theano.shared(value=numpy.ones((1), dtype='float32'), name='ones_scalar')
---
>             ones_scalar = theano.shared(value=np.ones((1), dtype='float32'), name='ones_scalar')
454d439
< 
534c519
<             ones_scalar = theano.shared(value=numpy.ones((1), dtype='float32'), name='ones_scalar')
---
>             ones_scalar = theano.shared(value=np.ones((1), dtype='float32'), name='ones_scalar')
805,806d789
< 
< 
890d872
< 
896,900c878,880
< 
<     NCE = 0
<     EVALUATION = 1
<     SAMPLING = 2
<     BEAM_SEARCH = 3
---
>     EVALUATION = 0
>     SAMPLING = 1
>     BEAM_SEARCH = 2
930,945d909
<         if self.add_latent_gaussian_per_utterance and self.add_latent_piecewise_per_utterance:
<             if self.condition_decoder_only_on_latent_variable:
<                 self.input_dim = self.latent_gaussian_per_utterance_dim + self.latent_piecewise_per_utterance_dim
<             else:
<                 self.input_dim += self.latent_gaussian_per_utterance_dim + self.latent_piecewise_per_utterance_dim
<         elif self.add_latent_gaussian_per_utterance:
<             if self.condition_decoder_only_on_latent_variable:
<                 self.input_dim = self.latent_gaussian_per_utterance_dim
<             else:
<                 self.input_dim += self.latent_gaussian_per_utterance_dim
<         elif self.add_latent_piecewise_per_utterance:
<             if self.condition_decoder_only_on_latent_variable:
<                 self.input_dim = self.latent_piecewise_per_utterance_dim
<             else:
<                 self.input_dim += self.latent_piecewise_per_utterance_dim
< 
986,989c950,953
<             if self.decoder_bias_type == 'all':
<                 self.Wd_s_q = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, self.qdim_decoder), name='Wd_s_q'))
<                 self.Wd_s_z = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, self.qdim_decoder), name='Wd_s_z'))
<                 self.Wd_s_r = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, self.qdim_decoder), name='Wd_s_r'))
---
>             # bias_type is always 'all'
>             self.Wd_s_q = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, self.qdim_decoder), name='Wd_s_q'))
>             self.Wd_s_z = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, self.qdim_decoder), name='Wd_s_z'))
>             self.Wd_s_r = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, self.qdim_decoder), name='Wd_s_r'))
1010,1018c974,982
<             if self.decoder_bias_type == 'all' or self.decoder_bias_type == 'selective':
<                 # Input gate
<                 self.Wd_s_i = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, self.qdim_decoder), name='Wd_s_i'))
<                 # Forget gate
<                 self.Wd_s_f = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, self.qdim_decoder), name='Wd_s_f'))
<                 # Cell input
<                 self.Wd_s = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, self.qdim_decoder), name='Wd_s'))
<                 # Output gate
<                 self.Wd_s_o = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, self.qdim_decoder), name='Wd_s_o'))
---
>             # bias_type is always 'all'
>             # Input gate
>             self.Wd_s_i = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, self.qdim_decoder), name='Wd_s_i'))
>             # Forget gate
>             self.Wd_s_f = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, self.qdim_decoder), name='Wd_s_f'))
>             # Cell input
>             self.Wd_s = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, self.qdim_decoder), name='Wd_s'))
>             # Output gate
>             self.Wd_s_o = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, self.qdim_decoder), name='Wd_s_o'))
1023,1067c987
< 
<         # Selective gating mechanism
<         if self.decoder_bias_type == 'selective':
<             # Selective gating mechanism is not compatible with bag-of-words decoder
<             assert not self.utterance_decoder_gating == "BOW"
< 
<             # Selective gating mechanism for LSTM
<             if self.utterance_decoder_gating == "LSTM":
<                 self.bd_sel = add_to_params(self.params, theano.shared(value=np.zeros((self.input_dim,), dtype='float32'), name='bd_sel'))
< 
<                 self.Wd_sel_s = add_to_params(self.params, \
<                                           theano.shared(value=NormalInit(self.rng, self.input_dim, self.input_dim), \
<                                                         name='Wd_sel_s'))
<                 # x_{n-1} -> g_r
<                 self.Wd_sel_e = add_to_params(self.params, \
<                                           theano.shared(value=NormalInit(self.rng, self.rankdim, self.input_dim), \
<                                                         name='Wd_sel_e'))
<                 # h_{n-1} -> g_r
<                 self.Wd_sel_h = add_to_params(self.params, \
<                                           theano.shared(value=NormalInit(self.rng, self.qdim_decoder, self.input_dim), \
<                                                         name='Wd_sel_h'))
<                 # c_{n-1} -> g_r
<                 self.Wd_sel_c = add_to_params(self.params, \
<                                           theano.shared(value=NormalInit(self.rng, self.qdim_decoder, self.input_dim), \
<                                                         name='Wd_sel_c'))
<             else: # Selective gating mechanism for GRU and plain decoder
<                 self.bd_sel = add_to_params(self.params, theano.shared(value=np.zeros((self.input_dim,), dtype='float32'), name='bd_sel'))
<                 self.Wd_s_q = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, self.qdim_decoder), name='Wd_s_q'))
<                 # s -> g_r
<                 self.Wd_sel_s = add_to_params(self.params, \
<                                           theano.shared(value=NormalInit(self.rng, self.input_dim, self.input_dim), \
<                                                         name='Wd_sel_s'))
<                 # x_{n-1} -> g_r
<                 self.Wd_sel_e = add_to_params(self.params, \
<                                           theano.shared(value=NormalInit(self.rng, self.rankdim, self.input_dim), \
<                                                         name='Wd_sel_e'))
<                 # h_{n-1} -> g_r
<                 self.Wd_sel_h = add_to_params(self.params, \
<                                           theano.shared(value=NormalInit(self.rng, self.qdim_decoder, self.input_dim), \
<                                                         name='Wd_sel_h'))
< 
< 
< 
< 
<         ######################   
---
>         ######################
1090,1091c1010,1011
<             if self.decoder_bias_type != 'first': 
<                 self.Wd_s_out = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, out_target_dim), name='Wd_s_out'))
---
>             # bias_type is always 'all'
>             self.Wd_s_out = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.input_dim, out_target_dim), name='Wd_s_out'))
1110,1112c1030,1031
<             if self.decoder_bias_type != 'first':
<                 pre_activ += T.dot(hs, self.Wd_s_out)
<                 # ^ if bias all, bias the deep output
---
>             # bias_type is always 'all'
>             pre_activ += T.dot(hs, self.Wd_s_out)  # bias the deep output
1133,1153d1051
<     
<     def output_nce(self, pre_activ, y, y_hat):
<         # returns a (timestep, bs, pos + neg) matrix (very small)
<         target_embedding = self.Wd_emb[y]
<         # ^ target embedding is (timestep x bs, rankdim)
<         noise_embedding = self.Wd_emb[y_hat]
<         # ^ noise embedding is (10, timestep x bs, rankdim)
<         
<         # pre_activ is (timestep x bs x rankdim)
<         pos_scores = (target_embedding * pre_activ).sum(2)
<         neg_scores = (noise_embedding * pre_activ).sum(3)
<  
<         pos_scores += self.bd_out[y]
<         neg_scores += self.bd_out[y_hat]
<          
<         pos_noise = self.parent.t_noise_probs[y] * 10
<         neg_noise = self.parent.t_noise_probs[y_hat] * 10
<         
<         pos_scores = - T.log(T.nnet.sigmoid(pos_scores - T.log(pos_noise)))
<         neg_scores = - T.log(1 - T.nnet.sigmoid(neg_scores - T.log(neg_noise))).sum(0)
<         return pos_scores + neg_scores
1169c1067
<         if mode == UtteranceDecoder.EVALUATION or mode == UtteranceDecoder.NCE:
---
>         if mode == UtteranceDecoder.EVALUATION:
1200c1098
<             assert mode == UtteranceDecoder.EVALUATION or mode == UtteranceDecoder.NCE
---
>             assert mode == UtteranceDecoder.EVALUATION
1215,1216d1112
<                 if self.decoder_bias_type == "selective":
<                     o_dec_info += [None, None]
1220,1221d1115
<                 if self.decoder_bias_type == "selective":
<                     o_dec_info += [None, None]
1225,1226d1118
<                 if self.decoder_bias_type == "selective":
<                     o_dec_info += [None, None] 
1231c1123
<             if mode == UtteranceDecoder.EVALUATION or mode == UtteranceDecoder.NCE: 
---
>             if mode == UtteranceDecoder.EVALUATION:
1246,1251d1137
<             # OBSOLETE:
<             #   if we are using selective bias, we should update our decoder_inp
<             #   to the step-selective decoder_inp
<             #   if self.decoder_bias_type == "selective":
<             #       decoder_inp = _res[1]
< 
1264,1266d1149
<         elif mode == UtteranceDecoder.NCE:
<             return self.output_nce(pre_activ, y, y_neg), hd, updates
< 
1304,1323c1187
<         if self.decoder_bias_type == 'selective':
<             rd_sel_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_sel_e) + T.dot(hd_tm1_tilde, self.Wd_sel_h) + T.dot(cd_tm1_tilde, self.Wd_sel_c) + T.dot(decoder_inp_t, self.Wd_sel_s) + self.bd_sel)
<             decoder_inpr_t = rd_sel_t * decoder_inp_t
< 
<             id_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_i) + T.dot(hd_tm1_tilde, self.Wd_hh_i) \
<                                   + T.dot(decoder_inpr_t, self.Wd_s_i) \
<                                   + T.dot(cd_tm1_tilde, self.Wd_c_i) + self.bd_i)
<             fd_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_f) + T.dot(hd_tm1_tilde, self.Wd_hh_f) \
<                                   + T.dot(decoder_inpr_t, self.Wd_s_f) \
<                                   + T.dot(cd_tm1_tilde, self.Wd_c_f) + self.bd_f)
<             cd_t = fd_t*cd_tm1_tilde + id_t*self.sent_rec_activation(T.dot(xd_t, self.Wd_in)  \
<                                   + T.dot(decoder_inpr_t, self.Wd_s) \
<                                   + T.dot(hd_tm1_tilde, self.Wd_hh) + self.bd_hh)
<             od_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_o) + T.dot(hd_tm1_tilde, self.Wd_hh_o) \
<                                   + T.dot(decoder_inpr_t, self.Wd_s_o) \
<                                   + T.dot(cd_t, self.Wd_c_o) + self.bd_o)
< 
<             # Concatenate output state and cell state into one vector
<             hd_t = T.concatenate([od_t*self.sent_rec_activation(cd_t), cd_t], axis=1)
<             output = (hd_t, decoder_inpr_t, rd_sel_t)
---
>         # code removed because never used: waeker performance
1327,1358c1191,1207
<         elif self.decoder_bias_type == 'all':
<             id_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_i) + T.dot(hd_tm1_tilde, self.Wd_hh_i) \
<                                   + T.dot(decoder_inp_t, self.Wd_s_i) \
<                                   + T.dot(cd_tm1_tilde, self.Wd_c_i) + self.bd_i)
<             fd_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_f) + T.dot(hd_tm1_tilde, self.Wd_hh_f) \
<                                   + T.dot(decoder_inp_t, self.Wd_s_f) \
<                                   + T.dot(cd_tm1_tilde, self.Wd_c_f) + self.bd_f)
<             cd_t = fd_t*cd_tm1_tilde + id_t*self.sent_rec_activation(T.dot(xd_t, self.Wd_in)  \
<                                   + T.dot(decoder_inp_t, self.Wd_s) \
<                                   + T.dot(hd_tm1_tilde, self.Wd_hh) + self.bd_hh)
<             od_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_o) + T.dot(hd_tm1_tilde, self.Wd_hh_o) \
<                                   + T.dot(decoder_inp_t, self.Wd_s_o) \
<                                   + T.dot(cd_t, self.Wd_c_o) + self.bd_o)
< 
<             # Concatenate output state and cell state into one vector
<             hd_t = T.concatenate([od_t*self.sent_rec_activation(cd_t), cd_t], axis=1)
<             output = (hd_t,)
<         else:
<             # Do not bias the decoder at every time, instead,
<             # force it to store very useful information in the first state.
<             id_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_i) + T.dot(hd_tm1_tilde, self.Wd_hh_i) \
<                                   + T.dot(cd_tm1_tilde, self.Wd_c_i) + self.bd_i)
<             fd_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_f) + T.dot(hd_tm1_tilde, self.Wd_hh_f) \
<                                   + T.dot(cd_tm1_tilde, self.Wd_c_f) + self.bd_f)
<             cd_t = fd_t*cd_tm1_tilde + id_t*self.sent_rec_activation(T.dot(xd_t, self.Wd_in_c)  \
<                                   + T.dot(hd_tm1_tilde, self.Wd_hh) + self.bd_hh)
<             od_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_o) + T.dot(hd_tm1_tilde, self.Wd_hh_o) \
<                                   + T.dot(cd_t, self.Wd_c_o) + self.bd_o)
< 
<             # Concatenate output state and cell state into one vector
<             hd_t = T.concatenate([od_t*self.sent_rec_activation(cd_t), cd_t], axis=1)
<             output = (hd_t,)
---
>         # bias_type is always 'all'
>         id_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_i) + T.dot(hd_tm1_tilde, self.Wd_hh_i) \
>                               + T.dot(decoder_inp_t, self.Wd_s_i) \
>                               + T.dot(cd_tm1_tilde, self.Wd_c_i) + self.bd_i)
>         fd_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_f) + T.dot(hd_tm1_tilde, self.Wd_hh_f) \
>                               + T.dot(decoder_inp_t, self.Wd_s_f) \
>                               + T.dot(cd_tm1_tilde, self.Wd_c_f) + self.bd_f)
>         cd_t = fd_t*cd_tm1_tilde + id_t*self.sent_rec_activation(T.dot(xd_t, self.Wd_in)  \
>                               + T.dot(decoder_inp_t, self.Wd_s) \
>                               + T.dot(hd_tm1_tilde, self.Wd_hh) + self.bd_hh)
>         od_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_o) + T.dot(hd_tm1_tilde, self.Wd_hh_o) \
>                               + T.dot(decoder_inp_t, self.Wd_s_o) \
>                               + T.dot(cd_t, self.Wd_c_o) + self.bd_o)
> 
>         # Concatenate output state and cell state into one vector
>         hd_t = T.concatenate([od_t*self.sent_rec_activation(cd_t), cd_t], axis=1)
>         output = (hd_t,)
1373,1386c1222
<         if self.decoder_bias_type == 'selective':
<             rd_sel_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_sel_e) + T.dot(hd_tm1, self.Wd_sel_h) + T.dot(decoder_inp_t, self.Wd_sel_s) + self.bd_sel)
<             decoder_inpr_t = rd_sel_t * decoder_inp_t
<              
<             rd_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_r) + T.dot(hd_tm1, self.Wd_hh_r) + self.bd_r)
<             zd_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_z) + T.dot(hd_tm1, self.Wd_hh_z) + self.bd_z)
<             hd_tilde = self.sent_rec_activation(T.dot(xd_t, self.Wd_in) \
<                                         + T.dot(rd_t * hd_tm1, self.Wd_hh) \
<                                         + T.dot(decoder_inpr_t, self.Wd_s_q) \
<                                         + self.bd_hh)
< 
< 
<             hd_t = (np.float32(1.) - zd_t) * hd_tm1 + zd_t * hd_tilde 
<             output = (hd_t, decoder_inpr_t, rd_sel_t, rd_t, zd_t, hd_tilde)
---
>         # code removed because never used: weaker performace
1390,1410c1226,1235
<         elif self.decoder_bias_type == 'all':
<         
<             rd_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_r) + T.dot(hd_tm1, self.Wd_hh_r) + T.dot(decoder_inp_t, self.Wd_s_r) + self.bd_r)
<             zd_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_z) + T.dot(hd_tm1, self.Wd_hh_z) + T.dot(decoder_inp_t, self.Wd_s_z) + self.bd_z)
<             hd_tilde = self.sent_rec_activation(T.dot(xd_t, self.Wd_in) \
<                                         + T.dot(rd_t * hd_tm1, self.Wd_hh) \
<                                         + T.dot(decoder_inp_t, self.Wd_s_q) \
<                                         + self.bd_hh)
<             hd_t = (np.float32(1.) - zd_t) * hd_tm1 + zd_t * hd_tilde 
<             output = (hd_t, rd_t, zd_t, hd_tilde)
< 
<         else:
<             # Do not bias the decoder at every time, instead,
<             # force it to store very useful information in the first state.
<             rd_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_r) + T.dot(hd_tm1, self.Wd_hh_r) + self.bd_r)
<             zd_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_z) + T.dot(hd_tm1, self.Wd_hh_z) + self.bd_z)
<             hd_tilde = self.sent_rec_activation(T.dot(xd_t, self.Wd_in) \
<                                         + T.dot(rd_t * hd_tm1, self.Wd_hh) \
<                                         + self.bd_hh) 
<             hd_t = (np.float32(1.) - zd_t) * hd_tm1 + zd_t * hd_tilde
<             output = (hd_t, rd_t, zd_t, hd_tilde)
---
>         # bias_type is always 'all'
>         rd_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_r) + T.dot(hd_tm1, self.Wd_hh_r) + T.dot(decoder_inp_t, self.Wd_s_r) + self.bd_r)
>         zd_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_in_z) + T.dot(hd_tm1, self.Wd_hh_z) + T.dot(decoder_inp_t, self.Wd_s_z) + self.bd_z)
>         hd_tilde = self.sent_rec_activation(T.dot(xd_t, self.Wd_in) \
>                                     + T.dot(rd_t * hd_tm1, self.Wd_hh) \
>                                     + T.dot(decoder_inp_t, self.Wd_s_q) \
>                                     + self.bd_hh)
>         hd_t = (np.float32(1.) - zd_t) * hd_tm1 + zd_t * hd_tilde
>         output = (hd_t, rd_t, zd_t, hd_tilde)
> 
1423,1445c1248,1253
<         if self.decoder_bias_type == 'first':
<             # Do not bias the decoder at every time, instead,
<             # force it to store very useful information in the first state.
<             hd_t = self.sent_rec_activation( T.dot(xd_t, self.Wd_in) \
<                                              + T.dot(hd_tm1, self.Wd_hh) \
<                                              + self.bd_hh )
<             output = (hd_t,)
<         elif self.decoder_bias_type == 'all':
<             hd_t = self.sent_rec_activation( T.dot(xd_t, self.Wd_in) \
<                                              + T.dot(hd_tm1, self.Wd_hh) \
<                                              + T.dot(decoder_inp_t, self.Wd_s_q) \
<                                              + self.bd_hh )
<             output = (hd_t,)
<         elif self.decoder_bias_type == 'selective':
<             rd_sel_t = T.nnet.sigmoid(T.dot(xd_t, self.Wd_sel_e) + T.dot(hd_tm1, self.Wd_sel_h) + T.dot(decoder_inp_t, self.Wd_sel_s) + self.bd_sel)
<             decoder_inpr_t = rd_sel_t * decoder_inp_t
<              
<             hd_t = self.sent_rec_activation( T.dot(xd_t, self.Wd_in) \
<                                         + T.dot(hd_tm1, self.Wd_hh) \
<                                         + T.dot(decoder_inpr_t, self.Wd_s_q) \
<                                         + self.bd_hh )
<             output = (hd_t, decoder_inpr_t, rd_sel_t)
< 
---
>         # bias_type is always 'all'
>         hd_t = self.sent_rec_activation( T.dot(xd_t, self.Wd_in) \
>                                          + T.dot(hd_tm1, self.Wd_hh) \
>                                          + T.dot(decoder_inp_t, self.Wd_s_q) \
>                                          + self.bd_hh )
>         output = (hd_t,)
1449,1668d1256
< class DialogLevelLatentGaussianEncoder(EncoderDecoderBase):
<     """
<     This class operates on hidden states at the dialogue level (inter-utterance level).
<     At the end of each utterance, the input from the utterance encoder(s) is transferred
<     to its hidden state. This hidden state is then transformed to output a mean and a (diagonal) 
<     covariance matrix, which parametrizes a latent Gaussian variable.
<     """
< 
<     def init_params(self):
<         """ Encoder weights """
< 
<         # Initialize input MLP
<         self.input_mlp = TwoLayerMLP(self.state, self.rng, self.input_dim, self.latent_dim*2, self.latent_dim, self, '_input_mlp_'+self.name)
<         self.params += self.input_mlp.params
< 
<         # Initialize mean and diagonal covariance matrix
<         self.Wl_mean_out = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.latent_dim, self.latent_dim), name='Wl_mean_out'+self.name))
<         self.bl_mean_out = add_to_params(self.params, theano.shared(value=np.zeros((self.latent_dim,), dtype='float32'), name='bl_mean_out'+self.name))
< 
<         self.Wl_std_out = add_to_params(self.params, theano.shared(value=NormalInit(self.rng, self.latent_dim, self.latent_dim), name='Wl_std_out'+self.name))
<         self.bl_std_out = add_to_params(self.params, theano.shared(value=np.zeros((self.latent_dim,), dtype='float32'), name='bl_std_out'+self.name))
< 
<     def plain_dialogue_step(self, h_t, m_t, hs_tm1):
<         if m_t.ndim >= 1:
<             m_t = m_t.dimshuffle(0, 'x')
< 
<         hs_t = (m_t) * hs_tm1 + (1 - m_t) * h_t
< 
<         return hs_t
< 
<     def build_encoder(self, h, x, xmask=None, latent_variable_mask=None, prev_state=None, **kwargs):
<         one_step = False
<         if len(kwargs):
<             one_step = True
< 
<         # if x.ndim == 2 then 
<         # x = (n_steps, batch_size)
<         if x.ndim == 2:
<             batch_size = x.shape[1]
<         # else x = (word_1, word_2, word_3, ...)
<         # or x = (last_word_1, last_word_2, last_word_3, ..)
<         else:
<             batch_size = 1
<         
<         # if it is not one_step then we initialize everything to 0  
<         if not one_step:
<             if prev_state:
<                 hs_0 = prev_state
<             else:
<                 hs_0 = T.alloc(np.float32(0), batch_size, self.latent_dim)
< 
<         # sampling mode (i.e. one step)
<         else:
<             # in this case x.ndim != 2
<             assert x.ndim != 2
<             assert 'prev_hs' in kwargs
<             hs_0 = kwargs['prev_hs']
< 
<         if xmask == None:
<             xmask = T.neq(x, self.eos_sym)
< 
<         if xmask.ndim == 1:
<             xmask = xmask.dimshuffle(0, 'x')
< 
<         if latent_variable_mask == None:
<             latent_variable_mask = T.eq(x, self.eos_sym)
< 
<         if latent_variable_mask.ndim == 1:
<             latent_variable_mask = latent_variable_mask.dimshuffle(0, 'x')
< 
< 
<         f_hier = self.plain_dialogue_step
<         o_hier_info = [hs_0]
< 
<         transformed_h, updates = self.input_mlp.build_output(h, latent_variable_mask)
< 
<         if not one_step:
<             _res,  _ = theano.scan(f_hier,\
<                                sequences=[transformed_h, xmask],\
<                                outputs_info=o_hier_info)
< 
<         # Just one step further
<         else:
<             _res = f_hier(transformed_h, xmask, hs_0)
< 
<         if isinstance(_res, list) or isinstance(_res, tuple):
<             hs = _res[0]
<         else:
<             hs = _res
< 
<         hs_mean = T.dot(hs, self.Wl_mean_out) + self.bl_mean_out
<         hs_var = T.nnet.softplus((T.dot(hs, self.Wl_std_out) + self.bl_std_out)) * self.scale_latent_gaussian_variable_variances
< 
<         hs_var = T.clip(hs_var, self.min_latent_gaussian_variable_variances, self.max_latent_gaussian_variable_variances)
< 
<         return [hs, hs_mean, hs_var], updates
< 
<     def __init__(self, state, input_dim, latent_dim, rng, parent, name):
<         EncoderDecoderBase.__init__(self, state, rng, parent)
<         self.input_dim = input_dim
<         self.latent_dim = latent_dim
<         self.name = name
<         self.init_params()
< 
< 
< class DialogLevelLatentPiecewiseEncoder(EncoderDecoderBase):
<     """
<     This class operates on hidden states at the dialogue level (inter-utterance level).
<     At the end of each utterance, the input from the utterance encoder(s) is transferred
<     to its hidden state. This hidden state is then transformed to output alpha vectors, which parametrize the vector of latent piecewise variables.
<     """
< 
<     def init_params(self):
<         """ Encoder weights """
<         # Initialize input MLP
<         self.input_mlp = TwoLayerMLP(self.state, self.rng, self.input_dim, self.latent_dim*2, self.latent_dim, self, '_input_mlp_'+self.name)
<         self.params += self.input_mlp.params
< 
<         # Alpha output parameters
<         self.Wl_alpha_out = add_to_params(self.params, theano.shared(value=NormalInit3D(self.rng, self.latent_dim, self.latent_dim, self.pieces_alpha), name='Wl_alpha_out'+self.name))
<         self.bl_alpha_out = add_to_params(self.params, theano.shared(value=np.zeros((self.latent_dim, self.pieces_alpha), dtype='float32'), name='bl_alpha_out'+self.name))
< 
< 
< 
<     def plain_dialogue_step(self, h_t, m_t, hs_tm1):
<         if m_t.ndim >= 1:
<             m_t = m_t.dimshuffle(0, 'x')
< 
<         hs_t = (m_t) * hs_tm1 + (1 - m_t) * h_t
< 
<         return hs_t
< 
<     def build_encoder(self, h, x, xmask=None, latent_variable_mask=None, prev_state=None, **kwargs):
<         one_step = False
<         if len(kwargs):
<             one_step = True
< 
<         # if x.ndim == 2 then 
<         # x = (n_steps, batch_size)
<         if x.ndim == 2:
<             batch_size = x.shape[1]
<         # else x = (word_1, word_2, word_3, ...)
<         # or x = (last_word_1, last_word_2, last_word_3, ..)
<         else:
<             batch_size = 1
<         
<         # if it is not one_step then we initialize everything to 0  
<         if not one_step:
<             if prev_state:
<                 hs_0 = prev_state
<             else:
<                 hs_0 = T.alloc(np.float32(0), batch_size, self.latent_dim)
< 
<         # sampling mode (i.e. one step)
<         else:
<             # in this case x.ndim != 2
<             assert x.ndim != 2
<             assert 'prev_hs' in kwargs
<             hs_0 = kwargs['prev_hs']
< 
<         if xmask == None:
<             xmask = T.neq(x, self.eos_sym)
< 
<         if xmask.ndim == 1:
<             xmask = xmask.dimshuffle(0, 'x')
< 
<         if latent_variable_mask == None:
<             latent_variable_mask = T.eq(x, self.eos_sym)
< 
<         if latent_variable_mask.ndim == 1:
<             latent_variable_mask = latent_variable_mask.dimshuffle(0, 'x')
< 
<         f_hier = self.plain_dialogue_step
<         o_hier_info = [hs_0]
< 
<         transformed_h, updates = self.input_mlp.build_output(h, latent_variable_mask)
< 
<         if not one_step:
<             _res,  _ = theano.scan(f_hier,\
<                                sequences=[transformed_h, xmask],\
<                                outputs_info=o_hier_info)
< 
<         # Just one step further
<         else:
<             _res = f_hier(transformed_h, xmask, hs_0)
< 
<         if isinstance(_res, list) or isinstance(_res, tuple):
<             hs = _res[0]
<         else:
<             hs = _res
< 
<         hs_reshaped = hs.reshape((1,hs.shape[0],hs.shape[1],hs.shape[2]))
< 
<         hs_repeated = T.repeat(hs_reshaped, self.pieces_alpha, axis=0).reshape((self.pieces_alpha, hs.shape[0], hs.shape[1], hs.shape[2])).dimshuffle(1,2,3,0)
< 
<         hs_alpha = BatchedDot(hs_repeated, self.Wl_alpha_out, True) + self.bl_alpha_out
< 
<         # hs: time steps x batch size x hidden dim
<         # hs_reshaped: time steps x batch size x hidden dim x pieces
<         # Wl_alpha_out: hidden dim x latent dim x pieces
<         # hs_alpha: time steps x batch size x latent dim x pieces
< 
<         if self.scale_latent_piecewise_variable_alpha_use_softplus:
<             hs_alpha = T.nnet.softplus(hs_alpha)*self.scale_alpha
<         else:
<             hs_alpha = T.exp(hs_alpha)*self.scale_alpha
< 
<         return [hs, hs_alpha], updates
< 
<     def __init__(self, state, input_dim, latent_dim, pieces_alpha, scale_alpha, rng, parent, name):
<         EncoderDecoderBase.__init__(self, state, rng, parent)
<         self.input_dim = input_dim
<         self.latent_dim = latent_dim
<         self.pieces_alpha = pieces_alpha
<         self.scale_alpha = scale_alpha
<         self.name = name
<         self.init_params()
< 
< 
< 
1743a1332
> 
1752,1754c1341,1342
<         Converts a list of words to a list
<         of word ids. Use unk_sym if a word is not
<         known.
---
>         Converts a list of word ids to a list of words.
>         Use unk_sym if a word is not known.
1766,1768c1354,1355
<         Converts a list of words to a list
<         of word ids. Use unk_sym if a word is not
<         known.
---
>         Converts a list of words to a list of word ids.
>         Use unk_sym if a word is not known.
1777c1364
<         reversed_seq = numpy.copy(seq)
---
>         reversed_seq = np.copy(seq)
1779c1366
<             eos_indices = numpy.where(seq[:, idx] == self.eos_sym)[0]
---
>             eos_indices = np.where(seq[:, idx] == self.eos_sym)[0]
1788,1789c1375,1380
<         updates = []
<          
---
>         """
>         Compute gradient updates for all parameters in order to minimize a given cost.
>         :param training_cost: cost to minimize
>         :param params: parameters to update
>         :return: updates as a list of tuples: [(param1, param1'), ...]
>         """
1792a1384
>         ###
1794c1386,1387
<         c = numpy.float32(self.cutoff)
---
>         ###
>         c = np.float32(self.cutoff)
1797a1391
>         # if norm_gs >= c then: normalization = c/norm_gs; else normalization = np.float32(1.)
1798a1393
>         # notfinite = (norm_gs == inf or norm_gs == -inf)
1800c1395
<          
---
> 
1802c1397
<             clip_grads.append((p, T.switch(notfinite, numpy.float32(.1) * p, g * normalization)))
---
>             clip_grads.append((p, T.switch(notfinite, np.float32(.1) * p, g * normalization)))
1837,1848c1432,1466
< 
<             self.debug_fn = theano.function(inputs=[self.x_data, self.x_data_reversed, 
<                                                              self.x_max_length,
<                                                              self.x_cost_mask,
<                                                              self.x_reset_mask, 
<                                                              self.ran_gaussian_cost_utterance,
<                                                              self.ran_uniform_cost_utterance,
<                                                              self.x_dropmask,
<                                                              self.returns],
<                                             outputs=[self.target_probs, self.debug_returns, self.training_x_cost_mask_flat, self.debug_training_y, self.debug_training_x, self.debug_target_probs_full],
<                                             on_unused_input='warn', 
<                                             name="debug_fn")
---
>             # Train HRED only:
>             if self.state['fixed_critic'] and not self.state['fixed_actor']:
>                 self.debug_fn = theano.function(inputs=[self.x_data,
>                                                         self.x_data_reversed,
>                                                         self.x_max_length,
>                                                         self.x_cost_mask,
>                                                         self.x_reset_mask,
>                                                         self.ran_gaussian_cost_utterance,
>                                                         self.ran_uniform_cost_utterance,
>                                                         self.x_dropmask,
>                                                         self.returns],
>                                                 outputs=[self.target_probs,
>                                                          self.debug_returns,
>                                                          self.training_x_cost_mask_flat,
>                                                          self.debug_training_y,
>                                                          self.debug_training_x,
>                                                          self.debug_target_probs_full],
>                                                 on_unused_input='warn',
>                                                 name="debug_fn")
>             # Train Critic network only:
>             elif self.state['fixed_actor'] and not self.state['fixed_critic']:
>                 # TODO: debug train function of critic only
>                 self.debug_fn = theano.function(inputs=[],
>                                                 outputs=[],
>                                                 updates=(),
>                                                 on_unused_input='warn',
>                                                 name='train_fn')
>             # Train both HRED and the critic network:
>             else:
>                 # TODO: debug train function of critic&actor? or define 2 train functions?
>                 self.debug_fn = theano.function(inputs=[],
>                                                 outputs=[],
>                                                 updates=(),
>                                                 on_unused_input='warn',
>                                                 name='train_fn')
1853,1860c1471,1482
<             self.train_fn = theano.function(inputs=[self.x_data, self.x_data_reversed, 
<                                                              self.x_max_length,
<                                                              self.x_cost_mask,
<                                                              self.x_reset_mask, 
<                                                              self.ran_gaussian_cost_utterance,
<                                                              self.ran_uniform_cost_utterance,
<                                                              self.x_dropmask,
<                                                              self.returns],
---
>             # Train HRED only:
>             if self.state['fixed_critic'] and not self.state['fixed_actor']:
>                 logger.debug("Building train function for actor")
>                 self.train_fn = theano.function(inputs=[self.x_data,
>                                                         self.x_data_reversed,
>                                                         self.x_max_length,
>                                                         self.x_cost_mask,
>                                                         self.x_reset_mask,
>                                                         self.ran_gaussian_cost_utterance,
>                                                         self.ran_uniform_cost_utterance,
>                                                         self.x_dropmask,
>                                                         self.returns],  # need returns for PolGrad
1862,1864c1484,1505
<                                                 updates=self.updates + self.state_updates, 
<                                                 on_unused_input='warn', 
<                                                 name="train_fn")   
---
>                                                 updates=self.updates + self.state_updates,
>                                                 on_unused_input='warn',
>                                                 name="train_fn")
>             # Train Critic network only:
>             elif self.state['fixed_actor'] and not self.state['fixed_critic']:
>                 logger.debug("Building train function for critic")
>                 # TODO: define train function of critic only
>                 self.train_fn = theano.function(inputs=[],
>                                                 outputs=[],
>                                                 updates=(),
>                                                 on_unused_input='warn',
>                                                 name='train_fn')
>             # Train both HRED and the critic network:
>             else:
>                 logger.debug("Building train function for both actor and critic")
>                 # TODO: define train function of critic&actor? or define 2 train functions?
>                 self.train_fn = theano.function(inputs=[],
>                                                 outputs=[],
>                                                 updates=(),
>                                                 on_unused_input='warn',
>                                                 name='train_fn')
> 
1871,1913c1512
< 
<             if self.add_latent_gaussian_per_utterance and self.add_latent_piecewise_per_utterance:
< 
<                 self.train_fn = theano.function(inputs=[self.x_data, self.x_data_reversed, 
<                                                              self.x_max_length,
<                                                              self.x_cost_mask,
<                                                              self.x_reset_mask, 
<                                                              self.ran_gaussian_cost_utterance,
<                                                              self.ran_uniform_cost_utterance,
<                                                              self.x_dropmask],
<                                                 outputs=[self.training_cost, self.kl_divergence_cost_acc, self.latent_gaussian_utterance_variable_approx_posterior_mean_var, self.latent_piecewise_utterance_variable_approx_posterior_alpha[-1], self.latent_piecewise_utterance_variable_prior_alpha[-1], self.kl_divergences_between_piecewise_prior_and_posterior, self.kl_divergences_between_gaussian_prior_and_posterior, self.latent_piecewise_posterior_sample],
<                                                 updates=self.updates + self.state_updates, 
<                                                 on_unused_input='warn', 
<                                                 name="train_fn")
< 
<             elif self.add_latent_gaussian_per_utterance:
<                 self.train_fn = theano.function(inputs=[self.x_data, self.x_data_reversed, 
<                                                              self.x_max_length,
<                                                              self_cost_mask,
<                                                              self.x_reset_mask, 
<                                                              self.ran_gaussian_cost_utterance,
<                                                              self.ran_uniform_cost_utterance,
<                                                              self.x_dropmask],
<                                                 outputs=[self.training_cost, self.kl_divergence_cost_acc, self.latent_gaussian_utterance_variable_approx_posterior_mean_var, self.kl_divergences_between_gaussian_prior_and_posterior],
<                                                 updates=self.updates + self.state_updates, 
<                                                 on_unused_input='warn', 
<                                                 name="train_fn")
< 
<             elif self.add_latent_piecewise_per_utterance:
<                 self.train_fn = theano.function(inputs=[self.x_data, self.x_data_reversed, 
<                                                              self.x_max_length,
<                                                              self.x_cost_mask,
<                                                              self.x_reset_mask, 
<                                                              self.ran_gaussian_cost_utterance,
<                                                              self.ran_uniform_cost_utterance,
<                                                              self.x_dropmask],
<                                                 outputs=[self.training_cost, self.kl_divergence_cost_acc, self.kl_divergences_between_piecewise_prior_and_posterior],
<                                                 updates=self.updates + self.state_updates, 
<                                                 on_unused_input='warn', 
<                                                 name="train_fn")
< 
<             else:
<                 self.train_fn = theano.function(inputs=[self.x_data, self.x_data_reversed, 
---
>             self.train_fn = theano.function(inputs=[self.x_data, self.x_data_reversed,
1931d1529
<                 
1945d1542
<                 
1958a1556
>         # Compile functions
1960,1968c1558,1593
<             # Compile functions
<             logger.debug("Building evaluation function")
< 
<             self.eval_fn = theano.function(inputs=[self.x_data, self.x_data_reversed, self.x_max_length, self.x_cost_mask, self.x_reset_mask, self.ran_gaussian_cost_utterance, self.ran_uniform_cost_utterance, self.x_dropmask, self.returns], 
<                                             outputs=[self.evaluation_cost, self.softmax_cost, self.kl_divergence_cost_acc], 
<                                             updates=self.state_updates,
<                                             on_unused_input='warn', name="eval_fn")
< 
< 
---
>             # Eval HRED only:
>             if self.state['fixed_critic'] and not self.state['fixed_actor']:
>                 logger.debug("Building evaluation function for actor")
>                 self.eval_fn = theano.function(inputs=[self.x_data,
>                                                        self.x_data_reversed,
>                                                        self.x_max_length,
>                                                        self.x_cost_mask,
>                                                        self.x_reset_mask,
>                                                        self.ran_gaussian_cost_utterance,
>                                                        self.ran_uniform_cost_utterance,
>                                                        self.x_dropmask,
>                                                        self.returns],  # need returns for PolGrad
>                                                outputs=[self.evaluation_cost,
>                                                         self.softmax_cost,
>                                                         self.kl_divergence_cost_acc],
>                                                updates=self.state_updates,
>                                                on_unused_input='warn',
>                                                name="eval_fn")
>             # Eval Critic network only:
>             elif self.state['fixed_actor'] and not self.state['fixed_critic']:
>                 logger.debug("Building evaluation function for critic")
>                 # TODO: define eval function of critic
>                 self.eval_fn = theano.function(inputs=[],
>                                                 outputs=[],
>                                                 updates=(),
>                                                 on_unused_input='warn',
>                                                 name='eval_fn')
>             # Train both HRED and the critic network:
>             else:
>                 logger.debug("Building evaluation function for both actor and critic")
>                 # TODO: define eval function of critic&actor? or define 2 eval functions?
>                 self.eval_fn = theano.function(inputs=[],
>                                                 outputs=[],
>                                                 updates=(),
>                                                 on_unused_input='warn',
>                                                 name='eval_fn')
1972,1992d1596
<     # Helper function used for the training with noise contrastive estimation (NCE).
<     # This function is currently not supported.
<     def build_nce_function(self):
<         if not hasattr(self, 'train_fn'):
<             # Compile functions
<             logger.debug("Building NCE train function")
< 
<             self.nce_fn = theano.function(inputs=[self.x_data, self.x_data_reversed, 
<                                                   self.y_neg, self.x_max_length, 
<                                                   self.x_cost_mask,
<                                                   self.x_reset_mask,
<                                                   self.ran_gaussian_cost_utterance,
<                                                   self.ran_uniform_cost_utterance,
<                                                   self.x_dropmask],
<                                             outputs=[self.training_cost, self.kl_divergence_cost_acc, self.latent_gaussian_utterance_variable_approx_posterior_mean_var],
<                                             updates=self.updates + self.state_updates, 
<                                             on_unused_input='warn', 
<                                             name="train_fn")
< 
<         return self.nce_fn
< 
1998,2000c1602,1612
< 
<             self.eval_fn = theano.function(inputs=[self.x_data, self.x_data_reversed, self.x_max_length, self.x_cost_mask, self.x_reset_mask, self.ran_gaussian_cost_utterance, self.ran_uniform_cost_utterance, self.x_dropmask], 
<                                             outputs=[self.evaluation_cost, self.softmax_cost, self.kl_divergence_cost_acc], 
---
>             self.eval_fn = theano.function(inputs=[self.x_data,
>                                                    self.x_data_reversed,
>                                                    self.x_max_length,
>                                                    self.x_cost_mask,
>                                                    self.x_reset_mask,
>                                                    self.ran_gaussian_cost_utterance,
>                                                    self.ran_uniform_cost_utterance,
>                                                    self.x_dropmask],
>                                             outputs=[self.evaluation_cost,
>                                                      self.softmax_cost,
>                                                      self.kl_divergence_cost_acc],
2004,2005d1615
< 
< 
2008,2131d1617
<     # Batch mean field update function.
<     def build_mf_update_function(self):
<         if not hasattr(self, 'mf_update_fn'):
<             # Compile functions
<             logger.debug("Building mean field update function")
< 
<             mf_params = []
< 
<             if self.add_latent_gaussian_per_utterance:
<                 mf_params.append(self.latent_gaussian_utterance_variable_approx_posterior_mean_mfbias)
<                 mf_params.append(self.latent_gaussian_utterance_variable_approx_posterior_var_mfbias)
< 
<             if self.add_latent_piecewise_per_utterance:
<                 mf_params.append(self.latent_piecewise_utterance_variable_approx_posterior_alpha_mfbias)
< 
<             mf_updates, _ = self.compute_updates(self.training_cost, mf_params)
< 
<             if self.add_latent_gaussian_per_utterance and self.add_latent_piecewise_per_utterance:
< 
<                 self.mf_update_fn = theano.function(inputs=[self.x_data, self.x_data_reversed, 
<                                                              self.x_max_length,
<                                                              self.x_cost_mask,
<                                                              self.x_reset_mask,
<                                                              self.ran_gaussian_cost_utterance,
<                                                              self.ran_uniform_cost_utterance,
<                                                              self.x_dropmask],
<                                                 outputs=[self.training_cost, self.kl_divergence_cost_acc,
<                                                          self.kl_divergences_between_piecewise_prior_and_posterior,
<                                                          self.kl_divergences_between_gaussian_prior_and_posterior],
<                                                 updates=mf_updates, 
<                                                 on_unused_input='warn', 
<                                                 name="mf_update_fn")
< 
<             elif self.add_latent_gaussian_per_utterance:
<                 self.mf_update_fn = theano.function(inputs=[self.x_data, self.x_data_reversed, 
<                                                              self.x_max_length,
<                                                              self.x_cost_mask,
<                                                              self.x_reset_mask, 
<                                                              self.ran_gaussian_cost_utterance,
<                                                              self.ran_uniform_cost_utterance,
<                                                              self.x_dropmask],
<                                                 outputs=[self.training_cost, self.kl_divergence_cost_acc,
<                                                          self.kl_divergences_between_gaussian_prior_and_posterior],
<                                                 updates=mf_updates, 
<                                                 on_unused_input='warn', 
<                                                 name="mf_update_fn")
< 
<             elif self.add_latent_piecewise_per_utterance:
<                 self.mf_update_fn = theano.function(inputs=[self.x_data, self.x_data_reversed, 
<                                                              self.x_max_length,
<                                                              self.x_cost_mask,
<                                                              self.x_reset_mask, 
<                                                              self.ran_gaussian_cost_utterance,
<                                                              self.ran_uniform_cost_utterance,
<                                                              self.x_dropmask],
<                                                 outputs=[self.training_cost, self.kl_divergence_cost_acc,\
<                                                         self.kl_divergences_between_piecewise_prior_and_posterior],
<                                                 updates=mf_updates, 
<                                                 on_unused_input='warn', 
<                                                 name="mf_update_fn")
<           
< 
<         return self.mf_update_fn
< 
<     def build_mf_reset_function(self):
<         if not hasattr(self, 'mf_reset_fn'):
<             # Compile functions
<             logger.debug("Building mean field reset function")
< 
<             mf_reset_update = []
< 
<             if self.add_latent_gaussian_per_utterance:
<                 mf_reset_update.append((self.latent_gaussian_utterance_variable_approx_posterior_mean_mfbias, T.zeros_like(self.latent_gaussian_utterance_variable_approx_posterior_mean_mfbias)))
<                 mf_reset_update.append((self.latent_gaussian_utterance_variable_approx_posterior_var_mfbias, T.zeros_like(self.latent_gaussian_utterance_variable_approx_posterior_var_mfbias)))
< 
<             if self.add_latent_piecewise_per_utterance:
<                 mf_reset_update.append((self.latent_piecewise_utterance_variable_approx_posterior_alpha_mfbias, T.zeros_like(self.latent_piecewise_utterance_variable_approx_posterior_alpha_mfbias)))
<             
< 
< 
<             self.mf_reset_fn = theano.function(inputs=[],
<                                                 outputs=[],
<                                                 updates=mf_reset_update, 
<                                                 on_unused_input='warn', 
<                                                 name="mf_reset_fn")
< 
<         return self.mf_reset_fn
< 
<     # Batch saliency evaluation function.
<     def build_saliency_eval_function(self):
<         if not hasattr(self, 'saliency_eval_fn'):
<             # Compile functions
<             logger.debug("Building saliency evaluation function")
< 
<             training_x = self.x_data[:(self.x_max_length-1)]
<             training_x_cost_mask = self.x_cost_mask[1:self.x_max_length]
<             latent_variable_mask = T.eq(training_x, self.eos_sym) * training_x_cost_mask
< 
<             # Compute Gaussian KL divergence saliency:
<             if self.add_latent_gaussian_per_utterance:
<                 kl_saliency_gaussian = \
<                     T.grad(T.sum(self.kl_divergences_between_gaussian_prior_and_posterior*latent_variable_mask), self.W_emb)**2
<                 kl_saliency_gaussian = T.sum(kl_saliency_gaussian, axis=-1)
<             else:
<                 kl_saliency_gaussian = T.sum(T.zeros_like(self.W_emb), axis=-1)
< 
< 
<             # Compute Piecewise KL divergence saliency:
<             if self.add_latent_piecewise_per_utterance:
<                 kl_saliency_piecewise = \
<                     T.grad(T.sum(self.kl_divergences_between_piecewise_prior_and_posterior*latent_variable_mask), self.W_emb)**2
<                 kl_saliency_piecewise = T.sum(kl_saliency_piecewise, axis=-1)
<             else:
<                 kl_saliency_piecewise = T.sum(T.zeros_like(self.W_emb), axis=-1)
< 
<             self.saliency_eval_fn = theano.function(inputs=[self.x_data, self.x_data_reversed, self.x_max_length, self.x_cost_mask, self.x_reset_mask, self.ran_gaussian_cost_utterance, self.ran_uniform_cost_utterance, self.x_dropmask], 
<                                             outputs=[kl_saliency_gaussian, kl_saliency_piecewise], 
<                                             updates=self.state_updates,
<                                             on_unused_input='warn', name="saliency_eval_fn")
< 
< 
< 
<         return self.saliency_eval_fn
< 
2133c1619
<     # Currently this function does not supported truncated computations.
---
>     # Currently this function does not support truncated computations.
2137,2236c1623
<             if self.add_latent_gaussian_per_utterance or self.add_latent_piecewise_per_utterance:
< 
<                 if self.condition_latent_variable_on_dialogue_encoder:
<                     if self.direct_connection_between_encoders_and_decoder:
<                         hs_to_condition_latent_variable_on = self.beam_hs.dimshuffle((0, 'x', 1))
<                     else:
<                         hs_to_condition_latent_variable_on = self.beam_hs.dimshuffle((0, 'x', 1))[:, :, 0:self.sdim]
<                 else:
<                     hs_to_condition_latent_variable_on = T.alloc(np.float32(0), self.beam_hs.shape[0], 1, self.beam_hs.shape[1])[:, :, 0:self.sdim]
< 
<                 if self.add_latent_gaussian_per_utterance:
<                     _gaussian_prior_out, _ = self.latent_gaussian_utterance_variable_prior_encoder.build_encoder(hs_to_condition_latent_variable_on, self.beam_x_data[-1])
< 
<                     latent_gaussian_utterance_variable_prior_mean = _gaussian_prior_out[1][-1]
<                     latent_gaussian_utterance_variable_prior_var = _gaussian_prior_out[2][-1]
< 
<                     prior_gaussian_sample = self.beam_ran_gaussian_cost_utterance * T.sqrt(latent_gaussian_utterance_variable_prior_var) + latent_gaussian_utterance_variable_prior_mean
< 
<                 if self.add_latent_piecewise_per_utterance:
<                     _piecewise_prior_out, _ = self.latent_piecewise_utterance_variable_prior_encoder.build_encoder(hs_to_condition_latent_variable_on, self.beam_x_data[-1])
< 
<                     latent_piecewise_utterance_variable_prior_alpha_hat = _piecewise_prior_out[1][-1]
< 
<                     # Apply alpha parameter trying / convolution
<                     if self.latent_piecewise_variable_alpha_parameter_tying:
<                         latent_piecewise_utterance_variable_prior_alpha = \
<                             T.zeros_like(latent_piecewise_utterance_variable_prior_alpha_hat)
< 
<                         for i in range(1, self.latent_piecewise_alpha_variables+1):
<                             normalization_constant = 0.0
<                             for j in range(1, self.latent_piecewise_alpha_variables+1):
<                                 # Compute current alpha_hat weight
<                                 w = numpy.exp(-self.latent_piecewise_variable_alpha_parameter_tying_beta*(i-j)**2)
< 
<                                 # Add weight to normalization constant
<                                 normalization_constant += w
< 
<                             normalization_constant = normalization_constant.astype('float32')
< 
<                             for j in range(1, self.latent_piecewise_alpha_variables+1):
<                                 # Compute normalized alpha_hat weight
<                                 wn = numpy.exp(-self.latent_piecewise_variable_alpha_parameter_tying_beta*(i-j)**2)\
<                                     /normalization_constant
<                                 wn = wn.astype('float32')
< 
<                                 # Add weight to alpha prior
<                                 latent_piecewise_utterance_variable_prior_alpha =                               \
<                                  T.inc_subtensor(latent_piecewise_utterance_variable_prior_alpha[:,:,i-1],\
<                                   wn*latent_piecewise_utterance_variable_prior_alpha_hat[:,:,j-1])
< 
<                     else:
<                         latent_piecewise_utterance_variable_prior_alpha = \
<                             latent_piecewise_utterance_variable_prior_alpha_hat
< 
< 
< 
< 
<                     latent_piecewise_utterance_prior_ki = latent_piecewise_utterance_variable_prior_alpha / self.latent_piecewise_alpha_variables
<                     latent_piecewise_utterance_prior_k = T.sum(latent_piecewise_utterance_prior_ki, axis=2)
< 
<                     # Sample from prior using inverse transform sampling:
<                     epsilon = self.beam_ran_uniform_cost_utterance
<                     prior_piecewise_sample = T.zeros_like(epsilon)
<                     for i in range(1, self.latent_piecewise_alpha_variables+1):
<                         lowerbound = T.zeros_like(epsilon)
<                         for j in range(1, i):
<                             lowerbound += (1.0/latent_piecewise_utterance_prior_k)*latent_piecewise_utterance_prior_ki[:, :,j-1]
<                         upperbound = lowerbound + (1.0/latent_piecewise_utterance_prior_k)*latent_piecewise_utterance_prior_ki[:, :,i-1]
<                         indicator = T.ge(epsilon, lowerbound)*T.lt(epsilon, upperbound)
< 
<                         prior_piecewise_sample += \
<                               indicator*((i - 1.0)/(self.latent_piecewise_alpha_variables) \
<                               + (latent_piecewise_utterance_prior_k/latent_piecewise_utterance_variable_prior_alpha[:,:,i-1])*(epsilon - lowerbound))
< 
< 
<                     # Transform sample to be in the range [-1, 1] with initial mean at zero.
<                     prior_piecewise_sample = 2.0*prior_piecewise_sample - 1.0
< 
< 
<                 if self.add_latent_gaussian_per_utterance and self.add_latent_piecewise_per_utterance:
<                     if self.condition_decoder_only_on_latent_variable:
<                         decoder_inp = T.concatenate([prior_gaussian_sample, prior_piecewise_sample], axis=1)
<                     else:
<                         decoder_inp = T.concatenate([self.beam_hs, prior_gaussian_sample, prior_piecewise_sample], axis=1)
<                 elif self.add_latent_gaussian_per_utterance:
<                     if self.condition_decoder_only_on_latent_variable:
<                         decoder_inp = prior_gaussian_sample
<                     else:
<                         decoder_inp = T.concatenate([self.beam_hs, prior_gaussian_sample], axis=1)
<                 else:
<                     if self.condition_decoder_only_on_latent_variable:
<                         decoder_inp = prior_piecewise_sample
<                     else:
<                         decoder_inp = T.concatenate([self.beam_hs, prior_piecewise_sample], axis=1)
< 
< 
< 
<             else:
<                 decoder_inp = self.beam_hs
< 
---
>             decoder_inp = self.beam_hs
2238c1625,1631
<             self.next_probs_fn = theano.function(inputs=[self.beam_hs, self.beam_hd, self.beam_source, self.beam_x_data, self.beam_ran_gaussian_cost_utterance, self.beam_ran_uniform_cost_utterance],
---
>             self.next_probs_fn = theano.function(
>                 inputs=[self.beam_hs,
>                         self.beam_hd,
>                         self.beam_source,
>                         self.beam_x_data,
>                         self.beam_ran_gaussian_cost_utterance,
>                         self.beam_ran_uniform_cost_utterance],
2254d1646
< 
2268,2339c1660,1664
< 
<             if self.add_latent_gaussian_per_utterance:
< 
<                 # Initialize hidden states to zero
<                 platent_gaussian_utterance_variable_approx_posterior = theano.shared(value=numpy.zeros((self.bs, self.latent_gaussian_per_utterance_dim), dtype='float32'), name='encoder_fn_platent_gaussian_utterance_variable_approx_posterior')
< 
<                 if self.condition_posterior_latent_variable_on_dcgm_encoder:
<                     platent_dcgm_avg = theano.shared(value=numpy.zeros((self.bs, self.rankdim), dtype='float32'), name='encoder_fn_platent_dcgm_avg')
<                     platent_dcgm_n = theano.shared(value=numpy.zeros((1, self.bs), dtype='float32'), name='encoder_fn_platent_dcgm_n')
< 
<                 # Create computational graph for latent variables
<                 latent_variable_mask = T.eq(self.x_data, self.eos_sym)
< 
<                 if self.condition_latent_variable_on_dialogue_encoder:
<                     hs_to_condition_latent_variable_on = hs_complete
<                 else:
<                     hs_to_condition_latent_variable_on = T.alloc(np.float32(0), hs.shape[0], hs.shape[1], hs.shape[2])
< 
<                 logger.debug("Initializing approximate posterior encoder for utterance-level latent variable")
<                 if self.bidirectional_utterance_encoder and not self.condition_posterior_latent_variable_on_dcgm_encoder:
<                     posterior_latent_input_size = self.sdim + self.qdim_encoder*2
<                     if self.direct_connection_between_encoders_and_decoder:
<                         posterior_latent_input_size += self.qdim_encoder*2
<                 else:
<                     posterior_latent_input_size = self.sdim + self.qdim_encoder
<                     if self.direct_connection_between_encoders_and_decoder:
<                         posterior_latent_input_size += self.qdim_encoder
< 
<                 if self.condition_posterior_latent_variable_on_dcgm_encoder:
<                     logger.debug("Build dcgm encoder")
<                     latent_dcgm_res, latent_dcgm_avg, latent_dcgm_n = self.dcgm_encoder.build_encoder(self.x_data, prev_state=[platent_dcgm_avg, platent_dcgm_n])
<                     h_future = self.utterance_encoder_rolledleft.build_encoder( \
<                                          latent_dcgm_res, \
<                                          self.x_data)
< 
<                 else:
<                     h_future = self.utterance_encoder_rolledleft.build_encoder( \
<                                          h, \
<                                          self.x_data)
< 
< 
<                 # Compute prior
<                 _prior_out, _ = self.latent_gaussian_utterance_variable_prior_encoder.build_encoder(hs_to_condition_latent_variable_on, self.x_data, latent_variable_mask=latent_variable_mask)
< 
<                 # Compute candidate posterior
<                 hs_and_h_future = T.concatenate([hs_to_condition_latent_variable_on, h_future], axis=2)
< 
<                 logger.debug("Build approximate posterior encoder for utterance-level latent variable")
<                 _posterior_out, _ = self.latent_gaussian_utterance_variable_approx_posterior_encoder.build_encoder( \
<                                          hs_and_h_future, \
<                                          self.x_data, \
<                                          latent_variable_mask=latent_variable_mask)
< 
< 
<                 # Use an MLP to interpolate between prior mean and candidate posterior mean and variance.
<                 latent_utterance_variable_approx_posterior_mean = self.gaussian_posterior_mean_combination.build_output(self.hs_and_h_future, _prior_out[1], _posterior_out[1])
<                 latent_utterance_variable_approx_posterior_var = self.posterior_variance_combination.build_output(self.hs_and_h_future, _prior_out[2], _posterior_out[2])
< 
<             # TODO: Implement posterior distribution encoding of piecewise latent variables here!
< 
<             if self.add_latent_gaussian_per_utterance:
<                 self.encoder_fn = theano.function(inputs=[self.x_data, self.x_data_reversed, \
<                              self.x_max_length], \
<                              outputs=[h, hs_complete], on_unused_input='warn', name="encoder_fn")
<                 #self.encoder_fn = theano.function(inputs=[self.x_data, self.x_data_reversed, \
<                 #             self.x_max_length], \
<                 #             outputs=[h, hs_complete, hs_and_h_future, latent_utterance_variable_approx_posterior_mean], on_unused_input='warn', name="encoder_fn")
<             else:
<                 self.encoder_fn = theano.function(inputs=[self.x_data, self.x_data_reversed, \
<                              self.x_max_length], \
<                              outputs=[h, hs_complete], on_unused_input='warn', name="encoder_fn")
< 
---
>             self.encoder_fn = theano.function(
>                 inputs=[self.x_data, self.x_data_reversed, self.x_max_length],
>                 outputs=[h, hs_complete],
>                 on_unused_input='warn',
>                 name="encoder_fn")
2349c1674
<         if not 'bidirectional_utterance_encoder' in state:
---
>         if 'bidirectional_utterance_encoder' not in state:
2355c1680
<         if not 'direct_connection_between_encoders_and_decoder' in state:
---
>         if 'direct_connection_between_encoders_and_decoder' not in state:
2358c1683
<         if not 'deep_direct_connection' in state:
---
>         if 'deep_direct_connection' not in state:
2361c1686
<         if not 'disable_dialogue_encoder' in state:
---
>         if 'disable_dialogue_encoder' not in state:
2372c1697
<         if not 'collaps_to_standard_rnn' in state:
---
>         if 'collaps_to_standard_rnn' not in state:
2375c1700
<         if not 'reset_utterance_decoder_at_end_of_utterance' in state:
---
>         if 'reset_utterance_decoder_at_end_of_utterance' not in state:
2378c1703
<         if not 'reset_utterance_encoder_at_end_of_utterance' in state:
---
>         if 'reset_utterance_encoder_at_end_of_utterance' not in state:
2383c1708
<         if not 'deep_dialogue_encoder_input' in state:
---
>         if 'deep_dialogue_encoder_input' not in state:
2386c1711
<         if not 'deep_utterance_decoder_input' in state:
---
>         if 'deep_utterance_decoder_input' not in state:
2389c1714
<         if not 'reset_hidden_states_between_subsequences' in state:
---
>         if 'reset_hidden_states_between_subsequences' not in state:
2392c1717
<         if not 'fix_encoder_parameters' in state:
---
>         if 'fix_encoder_parameters' not in state:
2395c1720
<         if not 'decoder_drop_previous_input_tokens' in state:
---
>         if 'decoder_drop_previous_input_tokens' not in state:
2401,2437d1725
<         if not 'add_latent_gaussian_per_utterance' in state:
<            state['add_latent_gaussian_per_utterance'] = False
<         if not 'latent_gaussian_per_utterance_dim' in state:
<            state['latent_gaussian_per_utterance_dim'] = 1
<         if not 'condition_latent_variable_on_dialogue_encoder' in state:
<            state['condition_latent_variable_on_dialogue_encoder'] = True
<         if not 'condition_posterior_latent_variable_on_dcgm_encoder' in state:
<            state['condition_posterior_latent_variable_on_dcgm_encoder'] = False
<         if not 'scale_latent_gaussian_variable_variances' in state:
<            state['scale_latent_gaussian_variable_variances'] = 0.01
<         if not 'condition_decoder_only_on_latent_variable' in state:
<            state['condition_decoder_only_on_latent_variable'] = False
< 
<         if not 'train_latent_variables_with_kl_divergence_annealing' in state:
<            state['train_latent_variables_with_kl_divergence_annealing'] = False
<         if state['train_latent_variables_with_kl_divergence_annealing']:
<             assert 'kl_divergence_annealing_rate' in state
< 
<         if not 'add_latent_piecewise_per_utterance' in state:
<             state['add_latent_piecewise_per_utterance'] = False
<         if not 'gate_latent_piecewise_per_utterance' in state:
<             state['gate_latent_piecewise_per_utterance'] = True
< 
<         if not 'constraint_latent_piecewise_variable_posterior' in state:
<             state['constraint_latent_piecewise_variable_posterior'] = True
<         if not 'scale_latent_piecewise_variable_prior_alpha' in state:
<             state['scale_latent_piecewise_variable_prior_alpha'] = 1.0
<         if not 'scale_latent_piecewise_variable_posterior_alpha' in state:
<             state['scale_latent_piecewise_variable_posterior_alpha'] = 1.0
<         if not 'scale_latent_piecewise_variable_alpha_use_softplus' in state:
<             state['scale_latent_piecewise_variable_alpha_use_softplus'] = True
<         if not 'latent_piecewise_variable_alpha_parameter_tying' in state:
<             state['latent_piecewise_variable_alpha_parameter_tying'] = False
< 
<         if not 'apply_meanfield_inference' in state:
<             state['apply_meanfield_inference'] = False
< 
2443c1731
<         if not 'compute_training_updates' in state:
---
>         if 'compute_training_updates' not in state:
2446c1734,1750
<         self.state = state
---
>         if 'decoder_bias_type' not in state:
>             state['decoder_bias_type'] = 'all'
>         if 'critic_decoder_bias_type' not in state:
>             state['critic_decoder_bias_type'] = 'all'
>         if 'use_nce' not in state:
>             state['use_nce'] = False
> 
>         if 'use_pg' not in state:
>             state['use_pg'] = False
>         if state['use_pg']:
>             if 'fixed_critic' not in state:
>                 state['fixed_critic'] = False  # default = train the critic
>             if 'fixed_actor' not in state:
>                 state['fixed_actor'] = False  # default = train the actor
>             assert not (state['fixed_critic'] and state['fixed_actor']), "nothing to train!"
> 
>         self.state = state  # TODO: choose between this ... Julian: Well, we do need to save the state inside the model to access those hyperparameters...
2449,2450c1753,1754
<         self.__dict__.update(state)
<         self.rng = numpy.random.RandomState(state['seed']) 
---
>         self.__dict__.update(state)  # TODO: ... and this! Why storing the same thing twice? Julian: I agree, it's a bit dumb to store these twice, but I think we can leave it like this for now.
>         self.rng = np.random.RandomState(state['seed'])
2455,2463d1758
<         # Probabilities for each term in the corpus used for noise contrastive estimation (NCE)
<         self.noise_probs = [x[2] for x in sorted(raw_dict, key=operator.itemgetter(1))]
<         self.noise_probs = numpy.array(self.noise_probs, dtype='float64')
<         self.noise_probs /= numpy.sum(self.noise_probs)
<         self.noise_probs = self.noise_probs ** 0.75
<         self.noise_probs /= numpy.sum(self.noise_probs)
<         
<         self.t_noise_probs = theano.shared(self.noise_probs.astype('float32'), 't_noise_probs')
< 
2478c1773
<         logger.debug("idim: " + str(self.idim))
---
>         logger.debug("number of words in dictionary = idim: " + str(self.idim))
2491,2492c1786,1797
<         self.returns = T.vector('returns')
<         
---
>         self.returns = T.vector('returns')  # used for policy gradient
> 
>         # Used for critic decoder network
>         self.context = T.imatrix('context')
>         self.context_reversed = T.imatrix('context_reversed')
>         context_mask = T.neq(self.context, self.state['eos_sym'])
>         self.y_star = T.imatrix('y_star')
>         self.y_star_reversed = T.imatrix('y_star_reversed')
>         y_star_mask = T.neq(self.y_star, self.state['eos_sym'])
>         self.y_sampled = T.imatrix('y_sampled')
>         y_sampled_mask = T.neq(self.y_sampled, self.state['eos_sym'])
> 
2503,2507d1807
<         #training_returns = self.returns.dimshuffle(0, 'x')
<         #training_returns = T.repeat(self.returns, self.x_max_length-1)
<         training_returns = self.returns
<         self.training_returns = training_returns
<         #training_returns = training_returns.dimshuffle(0, 'x')
2514c1814
< 
---
>         ###
2515a1816
>         ###
2522,2523c1823,1824
<             assert(self.idim == pretrained_embeddings[0].shape[0])
<             assert(self.rankdim == pretrained_embeddings[0].shape[1])
---
>             assert(self.idim == pretrained_embeddings[0].shape[0])  # recall: idim = #of words
>             assert(self.rankdim == pretrained_embeddings[0].shape[1])  # recall: rankdim = embedding size
2527,2528c1828,1829
<             self.W_emb_pretrained_mask = theano.shared(pretrained_embeddings[1].astype(numpy.float32), name='W_emb_mask')
<             self.W_emb = add_to_params(self.global_params, theano.shared(value=pretrained_embeddings[0].astype(numpy.float32), name='W_emb'))
---
>             self.W_emb_pretrained_mask = theano.shared(pretrained_embeddings[1].astype(np.float32), name='W_emb_mask')
>             self.W_emb = add_to_params(self.global_params, theano.shared(value=pretrained_embeddings[0].astype(np.float32), name='W_emb'))
2533c1834,1836
<         # Variables to store encoder and decoder states
---
>         #################################################
>         # Variables to store encoder and decoder states #
>         #################################################
2536,2537c1839,1840
<             self.ph_fwd = theano.shared(value=numpy.zeros((self.bs, self.qdim_encoder), dtype='float32'), name='ph_fwd')
<             self.ph_fwd_n = theano.shared(value=numpy.zeros((1, self.bs), dtype='int8'), name='ph_fwd_n')
---
>             self.ph_fwd = theano.shared(value=np.zeros((self.bs, self.qdim_encoder), dtype='float32'), name='ph_fwd')
>             self.ph_fwd_n = theano.shared(value=np.zeros((1, self.bs), dtype='int8'), name='ph_fwd_n')
2539,2540c1842,1843
<             self.ph_bck = theano.shared(value=numpy.zeros((self.bs, self.qdim_encoder), dtype='float32'), name='ph_bck')
<             self.ph_bck_n = theano.shared(value=numpy.zeros((1, self.bs), dtype='int8'), name='ph_bck_n')
---
>             self.ph_bck = theano.shared(value=np.zeros((self.bs, self.qdim_encoder), dtype='float32'), name='ph_bck')
>             self.ph_bck_n = theano.shared(value=np.zeros((1, self.bs), dtype='int8'), name='ph_bck_n')
2542c1845
<             self.phs = theano.shared(value=numpy.zeros((self.bs, self.sdim), dtype='float32'), name='phs')
---
>             self.phs = theano.shared(value=np.zeros((self.bs, self.sdim), dtype='float32'), name='phs')
2545c1848
<                 self.phs_dummy = theano.shared(value=numpy.zeros((self.bs, self.qdim_encoder*2), dtype='float32'), name='phs_dummy')
---
>                 self.phs_dummy = theano.shared(value=np.zeros((self.bs, self.qdim_encoder*2), dtype='float32'), name='phs_dummy')
2549,2550c1852,1853
<             self.ph = theano.shared(value=numpy.zeros((self.bs, self.qdim_encoder), dtype='float32'), name='ph')
<             self.ph_n = theano.shared(value=numpy.zeros((1, self.bs), dtype='int8'), name='ph_n')
---
>             self.ph = theano.shared(value=np.zeros((self.bs, self.qdim_encoder), dtype='float32'), name='ph')
>             self.ph_n = theano.shared(value=np.zeros((1, self.bs), dtype='int8'), name='ph_n')
2552c1855
<             self.phs = theano.shared(value=numpy.zeros((self.bs, self.sdim), dtype='float32'), name='phs')
---
>             self.phs = theano.shared(value=np.zeros((self.bs, self.sdim), dtype='float32'), name='phs')
2555c1858
<                 self.phs_dummy = theano.shared(value=numpy.zeros((self.bs, self.qdim_encoder), dtype='float32'), name='phs_dummy')
---
>                 self.phs_dummy = theano.shared(value=np.zeros((self.bs, self.qdim_encoder), dtype='float32'), name='phs_dummy')
2558c1861
<             self.phd = theano.shared(value=numpy.zeros((self.bs, self.qdim_decoder*2), dtype='float32'), name='phd')
---
>             self.phd = theano.shared(value=np.zeros((self.bs, self.qdim_decoder*2), dtype='float32'), name='phd')
2560c1863
<             self.phd = theano.shared(value=numpy.zeros((self.bs, self.qdim_decoder), dtype='float32'), name='phd')
---
>             self.phd = theano.shared(value=np.zeros((self.bs, self.qdim_decoder), dtype='float32'), name='phd')
2562,2576c1865,1867
<         if self.add_latent_gaussian_per_utterance:
<             self.platent_gaussian_utterance_variable_prior = theano.shared(value=numpy.zeros((self.bs, self.latent_gaussian_per_utterance_dim), dtype='float32'), name='platent_gaussian_utterance_variable_prior')
<             self.platent_gaussian_utterance_variable_approx_posterior = theano.shared(value=numpy.zeros((self.bs, self.latent_gaussian_per_utterance_dim), dtype='float32'), name='platent_gaussian_utterance_variable_approx_posterior')
< 
<         if self.add_latent_piecewise_per_utterance:
<             self.platent_piecewise_utterance_variable_prior = theano.shared(value=numpy.zeros((self.bs, self.latent_piecewise_per_utterance_dim), dtype='float32'), name='platent_piecewise_utterance_variable_prior')
<             self.platent_piecewise_utterance_variable_approx_posterior = theano.shared(value=numpy.zeros((self.bs, self.latent_piecewise_per_utterance_dim), dtype='float32'), name='platent_piecewise_utterance_variable_approx_posterior')
< 
<         if self.add_latent_gaussian_per_utterance or self.add_latent_piecewise_per_utterance:
<             if self.condition_posterior_latent_variable_on_dcgm_encoder:
<                 self.platent_dcgm_avg = theano.shared(value=numpy.zeros((self.bs, self.rankdim), dtype='float32'), name='platent_dcgm_avg')
<                 self.platent_dcgm_n = theano.shared(value=numpy.zeros((1, self.bs), dtype='float32'), name='platent_dcgm_n')
< 
< 
<         # Build utterance encoders
---
>         ############################
>         # Build utterance encoders #
>         ############################
2581c1872,1876
<             res_forward, res_forward_n, res_forward_updates = self.utterance_encoder_forward.build_encoder(training_x, xmask=training_hs_mask, prev_state=[self.ph_fwd, self.ph_fwd_n])
---
>             # Encoding training_x ...
>             res_forward, res_forward_n, res_forward_updates =\
>                 self.utterance_encoder_forward.build_encoder(training_x,
>                                                              xmask=training_hs_mask,
>                                                              prev_state=[self.ph_fwd, self.ph_fwd_n])
2586c1881,1885
<             res_backward, res_backward_n, res_backward_updates = self.utterance_encoder_backward.build_encoder(training_x_reversed, xmask=training_hs_mask, prev_state=[self.ph_bck, self.ph_bck_n])
---
>             # Encoding training_x_reversed ...
>             res_backward, res_backward_n, res_backward_updates =\
>                 self.utterance_encoder_backward.build_encoder(training_x_reversed,
>                                                               xmask=training_hs_mask,
>                                                               prev_state=[self.ph_bck, self.ph_bck_n])
2588c1887
<             # The encoder h embedding is a concatenation of final states of the forward and backward encoder RNNs
---
>             # The utterance encoder h embedding is a concatenation of final states of the forward and backward encoder RNNs
2590a1890,1911
>             self.enc_y_star = None  # Need encoding of the true response for critic network
>             self.enc_context = None  # Need encoding of the context for critic network
>             if self.state['use_pg'] and not self.state['fixed_critic']:
>                 # Encoding y_star ...
>                 res_y_star_forward, res_y_star_forward_n, res_y_star_forward_updates =\
>                     self.utterance_encoder_forward.build_encoder(self.y_star,
>                                                                  xmask=y_star_mask)
>                 # Encoding context ...
>                 res_context_forward, res_context_forward_n, res_context_forward_updates = \
>                     self.utterance_encoder_forward.build_encoder(self.context,
>                                                                  xmask=context_mask)
>                 # Encoding y_star_reversed ...
>                 res_y_star_backward, res_y_star_backward_n, res_y_star_backward_updates = \
>                     self.utterance_encoder_backward.build_encoder(self.y_star_reversed,
>                                                                  xmask=y_star_mask)
>                 # Encoding context_reversed ...
>                 res_context_backward, res_context_backward_n, res_context_backward_updates = \
>                     self.utterance_encoder_forward.build_encoder(self.context_reversed,
>                                                                  xmask=context_mask)
>                 self.enc_y_star = T.concatenate([res_y_star_forward, res_y_star_backward], axis=2)
>                 self.enc_context = T.concatenate([res_context_forward, res_context_backward], axis=2)
> 
2594d1914
< 
2596c1916,1920
< 
---
>             # Encoding training_x ...
>             res_forward, res_forward_n, res_forward_updates =\
>                 self.utterance_encoder.build_encoder(training_x,
>                                                      xmask=training_hs_mask,
>                                                      prev_state=[self.ph, self.ph_n])
2598,2601d1921
<             res_forward, res_forward_n, res_forward_updates = self.utterance_encoder.build_encoder(training_x, xmask=training_hs_mask, prev_state=[self.ph, self.ph_n])
< 
<             #res_y_star_forward, res_y_star_forward_n, res_y_star_forward_updates = self.utterance_encoder.build_encoder(y_star, xmask=training_hs_mask, prev_state=[self.ph, self.ph_n])
< 
2604c1924,1940
< 
---
>             self.enc_y_star = None  # Need encoding of the true response for critic network
>             self.enc_context = None  # Need encoding of the context for critic network
>             if self.state['use_pg'] and not self.state['fixed_critic']:
>                 # Encoding y_star ...
>                 res_y_star_forward, res_y_star_forward_n, res_y_star_forward_updates =\
>                     self.utterance_encoder.build_encoder(self.y_star,
>                                                          xmask=training_hs_mask)
>                 # Encoding context ...
>                 res_context_forward, res_context_forward_n, res_context_forward_updates = \
>                     self.utterance_encoder_forward.build_encoder(self.context,
>                                                                  xmask=context_mask)
>                 self.enc_y_star = res_y_star_forward
>                 self.enc_context = res_context_forward
> 
>         ###########################
>         # Building dialog encoder #
>         ###########################
2607d1942
< 
2608a1944
>         # Encoding training utterances...
2609a1946,1947
>         # Encoding context...
>         self.enc_context, _ = self.dialog_encoder.build_encoder(self.enc_context, self.context, x_mask=context_mask)
2610a1949
>         ####
2611a1951
>         ####
2622,2935c1962
< 
< 
<         # Compute quantities necessary for handling latent variables
<         if self.add_latent_gaussian_per_utterance or self.add_latent_piecewise_per_utterance:
<             # Define list storing variable updates related to latent modules
<             self.latent_variable_updates = []
< 
<             # Define KL divergence cost
<             self.kl_divergence_cost = training_x_cost_mask*0
< 
<             # Compute mask over latent variables. 
<             # One means that a variable is part of the computational graph and zero that it's not.
<             latent_variable_mask = T.eq(training_x, self.eos_sym) * training_x_cost_mask
< 
<             # We consider two kinds of prior: one case where the latent variables are 
<             # conditioned on the dialogue encoder, and one case where they are not conditioned on anything.
<             if self.condition_latent_variable_on_dialogue_encoder:
<                 if self.direct_connection_between_encoders_and_decoder:
<                     self.hs_to_condition_latent_variable_on = T.concatenate([self.hs, self.hs_dummy], axis=2)
<                     if self.bidirectional_utterance_encoder:
<                         prior_latent_input_size = self.sdim + self.qdim_encoder*2
<                     else:
<                         prior_latent_input_size = self.sdim + self.qdim_encoder
<                 else:
<                     self.hs_to_condition_latent_variable_on = self.hs
<                     prior_latent_input_size = self.sdim
<             else:
<                 self.hs_to_condition_latent_variable_on = T.alloc(np.float32(0), self.hs.shape[0], self.hs.shape[1], self.hs.shape[2])
<                 prior_latent_input_size = self.sdim
< 
< 
<             if self.bidirectional_utterance_encoder and not self.condition_posterior_latent_variable_on_dcgm_encoder:
<                 posterior_latent_input_size = prior_latent_input_size + self.qdim_encoder*2
<             else:
<                 posterior_latent_input_size = prior_latent_input_size + self.qdim_encoder
< 
<             # Retrieve hidden state at the end of next utterance from the utterance encoders
<             # (or at the end of the batch, if there are no end-of-token symbols at the end of the batch)
<             if self.bidirectional_utterance_encoder:
<                 self.utterance_encoder_rolledleft = DialogLevelRollLeft(self.state, self.qdim_encoder, self.rng, self)
<             else:
<                 self.utterance_encoder_rolledleft = DialogLevelRollLeft(self.state, self.qdim_encoder*2, self.rng, self)
< 
<             if self.condition_posterior_latent_variable_on_dcgm_encoder:
<                 logger.debug("Initializing DCGM encoder for conditioning input to the utterance-level latent variable")
< 
<                 self.dcgm_encoder = DCGMEncoder(self.state, self.rng, self.W_emb, self.qdim_encoder, self, 'latent_dcgm_encoder')
<                 logger.debug("Build DCGM encoder")
<                 latent_dcgm_res, self.latent_dcgm_avg, self.latent_dcgm_n = self.dcgm_encoder.build_encoder(training_x, xmask=training_hs_mask, prev_state=[self.platent_dcgm_avg, self.platent_dcgm_n])
< 
<                 self.h_future = self.utterance_encoder_rolledleft.build_encoder( \
<                                      latent_dcgm_res, \
<                                      training_x, \
<                                      xmask=training_hs_mask)
<             else:
<                 self.h_future = self.utterance_encoder_rolledleft.build_encoder( \
<                                      self.h, \
<                                      training_x, \
<                                      xmask=training_hs_mask)
< 
<             self.hs_and_h_future = T.concatenate([self.hs_to_condition_latent_variable_on, self.h_future], axis=2)
< 
< 
< 
< 
< 
< 
< 
< 
< 
<         # We initialize the multivariate Gaussian latent variables
<         if self.add_latent_gaussian_per_utterance:
<             logger.debug("Initializing prior encoder for utterance-level latent multivariate Gaussian variables")
< 
<             self.latent_gaussian_utterance_variable_prior_encoder = DialogLevelLatentGaussianEncoder(self.state, prior_latent_input_size, self.latent_gaussian_per_utterance_dim, self.rng, self, 'latent_gaussian_utterance_prior')
< 
<             logger.debug("Build prior encoder for utterance-level latent multivariate Gaussian variables")
<             _prior_gaussian_out, _prior_gaussian_updates = self.latent_gaussian_utterance_variable_prior_encoder.build_encoder(self.hs_to_condition_latent_variable_on, training_x, xmask=training_hs_mask, latent_variable_mask=latent_variable_mask, prev_state=self.platent_gaussian_utterance_variable_prior)
<             self.latent_variable_updates += _prior_gaussian_updates
< 
<             self.latent_gaussian_utterance_variable_prior = _prior_gaussian_out[0]
<             self.latent_gaussian_utterance_variable_prior_mean = _prior_gaussian_out[1]
<             self.latent_gaussian_utterance_variable_prior_var = _prior_gaussian_out[2]
< 
<             self.latent_gaussian_utterance_variable_approx_posterior_encoder = DialogLevelLatentGaussianEncoder(self.state, posterior_latent_input_size, self.latent_gaussian_per_utterance_dim, self.rng, self, 'latent_gaussian_utterance_approx_posterior')
< 
<             logger.debug("Build approximate posterior encoder for utterance-level latent multivariate Gaussian variables")
<             _posterior_gaussian_out, _posterior_gaussian_updates =                                  \
<                     self.latent_gaussian_utterance_variable_approx_posterior_encoder.build_encoder( \
<                                      self.hs_and_h_future,                                          \
<                                      training_x,                                                    \
<                                      xmask=training_hs_mask,                                        \
<                                      latent_variable_mask=latent_variable_mask,                     \
<                                      prev_state=self.platent_gaussian_utterance_variable_approx_posterior)
<             self.latent_variable_updates += _posterior_gaussian_updates
< 
<             self.latent_gaussian_utterance_variable_approx_posterior = _posterior_gaussian_out[0]
< 
<             # Use an MLP to interpolate between prior mean and candidate posterior mean.
<             # This allows model to revert back to prior easily for dimensions, where it is uncertain.
<             self.gaussian_posterior_mean_combination = LinearCombination(self.state, posterior_latent_input_size, self.latent_gaussian_per_utterance_dim, False, 0.0, 0.0, self.rng, self, 'latent_gaussian_utterance_approx_posterior_mean_combination')
<             self.latent_gaussian_utterance_variable_approx_posterior_mean = self.gaussian_posterior_mean_combination.build_output(self.hs_and_h_future, self.latent_gaussian_utterance_variable_prior_mean, _posterior_gaussian_out[1])
< 
< 
<             # Use an MLP to interpolate between prior variance and candidate posterior variance.
<             # This allows model to revert back to prior easily for dimensions, where it is uncertain.
<             self.posterior_variance_combination = LinearCombination(self.state, posterior_latent_input_size, self.latent_gaussian_per_utterance_dim, True, self.min_latent_gaussian_variable_variances, self.max_latent_gaussian_variable_variances, self.rng, self, 'latent_gaussian_utterance_approx_posterior_variance_combination')
<             self.latent_gaussian_utterance_variable_approx_posterior_var = self.posterior_variance_combination.build_output(self.hs_and_h_future, self.latent_gaussian_utterance_variable_prior_var, _posterior_gaussian_out[2])
< 
< 
<             # Apply mean-field inference?
<             if self.apply_meanfield_inference:
<                 self.latent_gaussian_utterance_variable_approx_posterior_mean_mfbias = \
<                     theano.shared(value=numpy.zeros((self.bs, self.latent_gaussian_per_utterance_dim), dtype='float32'), name='latent_gaussian_utterance_variable_approx_posterior_mean_mfbias')
<                 self.latent_gaussian_utterance_variable_approx_posterior_var_mfbias = \
<                     theano.shared(value=numpy.zeros((self.bs, self.latent_gaussian_per_utterance_dim), dtype='float32'), name='latent_gaussian_utterance_variable_approx_posterior_var_mfbias')
< 
<                 self.latent_gaussian_utterance_variable_approx_posterior_mean += \
<                     self.latent_gaussian_utterance_variable_approx_posterior_mean_mfbias.dimshuffle('x', 0, 1)
< 
<                 self.latent_gaussian_utterance_variable_approx_posterior_var += \
<                     T.maximum(self.latent_gaussian_utterance_variable_approx_posterior_var_mfbias.dimshuffle('x', 0, 1), - self.latent_gaussian_utterance_variable_approx_posterior_var + 0.000001)
< 
< 
< 
< 
<             self.latent_gaussian_utterance_variable_approx_posterior_mean_var = T.sum(T.mean(self.latent_gaussian_utterance_variable_approx_posterior_var,axis=2)*latent_variable_mask) / (T.sum(latent_variable_mask) + 0.0000001)
< 
<             # Sample utterance latent variable from posterior
<             self.latent_gaussian_posterior_sample = self.ran_gaussian_cost_utterance[:(self.x_max_length-1)] * T.sqrt(self.latent_gaussian_utterance_variable_approx_posterior_var) + self.latent_gaussian_utterance_variable_approx_posterior_mean
< 
<             # Compute KL divergence cost
<             mean_diff_squared = (self.latent_gaussian_utterance_variable_prior_mean \
<                                  - self.latent_gaussian_utterance_variable_approx_posterior_mean)**2
< 
<             logger.debug("Build KL divergence cost for latent multivariate Gaussian variables")
<             #self.kl_divergences_between_gaussian_prior_and_posterior                                      \
<             #    = T.maximum(0.0, (T.sum(self.latent_gaussian_utterance_variable_approx_posterior_var      \
<             #                            /self.latent_gaussian_utterance_variable_prior_var, axis=2)       \
<             #       + T.sum(mean_diff_squared/self.latent_gaussian_utterance_variable_prior_var, axis=2)   \
<             #       - state['latent_gaussian_per_utterance_dim']                                           \
<             #       + T.sum(T.log(self.latent_gaussian_utterance_variable_prior_var), axis=2)              \
<             #       - T.sum(T.log(self.latent_gaussian_utterance_variable_approx_posterior_var), axis=2)   \
<             #      ) / 2)
< 
<             # Numerically stable without truncation at zero
<             self.kl_divergences_between_gaussian_prior_and_posterior                                      \
<                 = (T.sum(self.latent_gaussian_utterance_variable_approx_posterior_var      \
<                                         /self.latent_gaussian_utterance_variable_prior_var, axis=2)       \
<                    + T.sum(mean_diff_squared/self.latent_gaussian_utterance_variable_prior_var, axis=2)   \
<                    - state['latent_gaussian_per_utterance_dim']                                           \
<                    + T.sum(T.log(self.latent_gaussian_utterance_variable_prior_var), axis=2)              \
<                    - T.sum(T.log(self.latent_gaussian_utterance_variable_approx_posterior_var), axis=2))/2
< 
< 
< 
<             self.kl_divergence_cost += self.kl_divergences_between_gaussian_prior_and_posterior*latent_variable_mask
< 
<         else:
<             self.latent_gaussian_utterance_variable_approx_posterior_mean_var = theano.shared(value=numpy.float(0))
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
< 
<         # We initialize the stochastic latent variables
<         # platent_piecewise_utterance_variable_prior
<         if self.add_latent_piecewise_per_utterance:
<             # Compute prior
<             logger.debug("Initializing prior encoder for utterance-level latent piecewise variables")
<             self.latent_piecewise_utterance_variable_prior_encoder = DialogLevelLatentPiecewiseEncoder(self.state, prior_latent_input_size, self.latent_piecewise_per_utterance_dim, self.latent_piecewise_alpha_variables, self.scale_latent_piecewise_variable_prior_alpha, self.rng, self, 'latent_piecewise_utterance_prior')
< 
<             logger.debug("Build prior encoder for utterance-level latent piecewise variables")
<             _prior_piecewise_out, _prior_piecewise_updates = self.latent_piecewise_utterance_variable_prior_encoder.build_encoder(self.hs_to_condition_latent_variable_on, training_x, xmask=training_hs_mask, latent_variable_mask=latent_variable_mask, prev_state=self.platent_piecewise_utterance_variable_prior)
<             self.latent_variable_updates += _prior_piecewise_updates
< 
<             self.latent_piecewise_utterance_variable_prior = _prior_piecewise_out[0]
<             self.latent_piecewise_utterance_variable_prior_alpha_hat = _prior_piecewise_out[1]
< 
< 
<             # Compute posterior using prior
<             logger.debug("Initializing approximate posterior encoder for utterance-level latent piecewise variables")
<             self.latent_piecewise_utterance_variable_approx_posterior_encoder = DialogLevelLatentPiecewiseEncoder(self.state, posterior_latent_input_size, self.latent_piecewise_per_utterance_dim, self.latent_piecewise_alpha_variables, self.scale_latent_piecewise_variable_posterior_alpha, self.rng, self, 'latent_piecewise_utterance_approx_posterior')
< 
<             logger.debug("Build approximate posterior encoder for utterance-level latent piecewise variables")
<             _posterior_piecewise_out, _posterior_piecewise_updates =                                    \
<                      self.latent_piecewise_utterance_variable_approx_posterior_encoder.build_encoder( \
<                                      self.hs_and_h_future, \
<                                      training_x, \
<                                      xmask=training_hs_mask, \
<                                      latent_variable_mask=latent_variable_mask, \
<                                      prev_state=self.platent_piecewise_utterance_variable_approx_posterior)
<             self.latent_variable_updates += _posterior_piecewise_updates
< 
<             self.latent_piecewise_utterance_variable_approx_posterior = _posterior_piecewise_out[0]
< 
<             # Apply gating mechanism for linear interpolation
<             if self.gate_latent_piecewise_per_utterance:
<                 self.piecewise_posterior_mean_combination = LinearCombination(self.state, posterior_latent_input_size, self.latent_piecewise_per_utterance_dim, False, 0.0, 0.0, self.rng, self, 'latent_piecewise_utterance_approx_posterior_alpha_combination')
<                 self.latent_piecewise_utterance_variable_approx_posterior_alpha_hat = self.piecewise_posterior_mean_combination.build_output(self.hs_and_h_future, self.latent_piecewise_utterance_variable_prior_alpha_hat.dimshuffle(0, 1, 3, 2), _posterior_piecewise_out[1].dimshuffle(0, 1, 3, 2)).dimshuffle(0, 1, 3, 2)
<             else:
<                 self.latent_piecewise_utterance_variable_approx_posterior_alpha_hat = _posterior_piecewise_out[1]
< 
< 
<             # Apply alpha parameter trying / convolution
<             if self.latent_piecewise_variable_alpha_parameter_tying:
<                 self.latent_piecewise_utterance_variable_prior_alpha = \
<                     T.zeros_like(self.latent_piecewise_utterance_variable_prior_alpha_hat)
<                 self.latent_piecewise_utterance_variable_approx_posterior_alpha = \
<                     T.zeros_like(self.latent_piecewise_utterance_variable_approx_posterior_alpha_hat)
< 
<                 for i in range(1, self.latent_piecewise_alpha_variables+1):
<                     normalization_constant = 0.0
<                     for j in range(1, self.latent_piecewise_alpha_variables+1):
<                         # Compute current alpha_hat weight
<                         w = numpy.exp(-self.latent_piecewise_variable_alpha_parameter_tying_beta*(i-j)**2)
< 
<                         # Add weight to normalization constant
<                         normalization_constant += w
< 
<                     normalization_constant = normalization_constant.astype('float32')
< 
<                     for j in range(1, self.latent_piecewise_alpha_variables+1):
<                         # Compute normalized alpha_hat weight
<                         wn = numpy.exp(-self.latent_piecewise_variable_alpha_parameter_tying_beta*(i-j)**2)\
<                             /normalization_constant
<                         wn = wn.astype('float32')
< 
<                         # Add weight to alpha prior
<                         self.latent_piecewise_utterance_variable_prior_alpha =                               \
<                          T.inc_subtensor(self.latent_piecewise_utterance_variable_prior_alpha[:,:,:,i-1],\
<                           wn*self.latent_piecewise_utterance_variable_prior_alpha_hat[:,:, :,j-1])
< 
<                         # Add weight to alpha posterior
<                         self.latent_piecewise_utterance_variable_approx_posterior_alpha =                   \
<                          T.inc_subtensor(self.latent_piecewise_utterance_variable_approx_posterior_alpha[:,:,:,i-1],\
<                          wn*self.latent_piecewise_utterance_variable_approx_posterior_alpha_hat[:,:, :,j-1])
< 
< 
<             else:
<                 self.latent_piecewise_utterance_variable_prior_alpha = \
<                     self.latent_piecewise_utterance_variable_prior_alpha_hat
<                 self.latent_piecewise_utterance_variable_approx_posterior_alpha = \
<                     self.latent_piecewise_utterance_variable_approx_posterior_alpha_hat
< 
< 
<             if self.apply_meanfield_inference:
<                 self.latent_piecewise_utterance_variable_approx_posterior_alpha_mfbias = \
<                     theano.shared(value=numpy.zeros((self.bs, self.latent_piecewise_per_utterance_dim,\
<                                   self.latent_piecewise_alpha_variables), dtype='float32'),\
<                                   name='latent_piecewise_utterance_variable_approx_posterior_alpha_mfbias')
< 
<                 self.latent_piecewise_utterance_variable_approx_posterior_alpha += \
<                     T.exp(self.latent_piecewise_utterance_variable_approx_posterior_alpha_mfbias.dimshuffle('x', 0, 1, 2))
< 
< 
<             # Compute prior normalization constants:
<             latent_piecewise_utterance_prior_ki = self.latent_piecewise_utterance_variable_prior_alpha / self.latent_piecewise_alpha_variables
<             latent_piecewise_utterance_prior_k = T.sum(latent_piecewise_utterance_prior_ki, axis=3)
< 
< 
< 
<             # epsilon: a standard uniform sample in range [0, 1];
<             #          shape: (time steps x batch size x number of piecewise latent variables)
<             # latent_piecewise_posterior_sample: initialized to zeros;
<             #          shape: (time steps x batch size x number of piecewise latent variables)
<             # latent_piecewise_alpha_variables: integer representing number of pieces (I set this to 3)
<             # latent_piecewise_utterance_variable_approx_posterior_alpha:
<             #      un-normalized a values, i.e. the height of each rectangle;
<             #      shape: (time steps x batch size x number of piecewise latent variables x latent_piecewise_alpha_variables)
< 
< 
<             # Compute posterior normalization constants:
<             # latent_piecewise_utterance_variable_prior_alpha: time steps x batch sizes x latent dim x pieces
<             latent_piecewise_utterance_posterior_ki = self.latent_piecewise_utterance_variable_approx_posterior_alpha / self.latent_piecewise_alpha_variables
<             latent_piecewise_utterance_posterior_k = T.sum(latent_piecewise_utterance_posterior_ki, axis=3)
< 
<             epsilon = self.ran_uniform_cost_utterance[:(self.x_max_length-1)]
< 
<             # Sample from posterior using inverse transform sampling:
<             self.latent_piecewise_posterior_sample = T.zeros_like(epsilon)
<             for i in range(1, self.latent_piecewise_alpha_variables+1):
<                 lowerbound = T.zeros_like(epsilon)
<                 for j in range(1, i):
<                     lowerbound += (1.0/latent_piecewise_utterance_posterior_k)*latent_piecewise_utterance_posterior_ki[:,:, :,j-1]
<                 upperbound = lowerbound + (1.0/latent_piecewise_utterance_posterior_k)*latent_piecewise_utterance_posterior_ki[:,:, :,i-1]
<                 indicator = T.ge(epsilon, lowerbound)*T.lt(epsilon, upperbound)
< 
<                 self.latent_piecewise_posterior_sample += \
<                       indicator*((i - 1.0)/(self.latent_piecewise_alpha_variables) \
<                       + (latent_piecewise_utterance_posterior_k/self.latent_piecewise_utterance_variable_approx_posterior_alpha[:,:,:,i-1])*(epsilon - lowerbound))
< 
<             # Transform sample to be in the range [-1, 1] with initial mean at zero.
<             # This is considered as part of the decoder and does not affect KL divergence computations.
<             self.latent_piecewise_posterior_sample = 2.0*self.latent_piecewise_posterior_sample - 1.0
< 
<             # Next, compute KL divergence cost
<             self.kl_divergences_between_piecewise_prior_and_posterior = T.zeros_like(latent_variable_mask)
<             for i in range(1, self.latent_piecewise_alpha_variables+1):
<                 self.kl_divergences_between_piecewise_prior_and_posterior += T.sum((1.0/self.latent_piecewise_alpha_variables)*(self.latent_piecewise_utterance_variable_approx_posterior_alpha[:,:,:,i-1]/latent_piecewise_utterance_posterior_k)*(T.log(self.latent_piecewise_utterance_variable_approx_posterior_alpha[:,:,:,i-1]/latent_piecewise_utterance_posterior_k)-T.log(self.latent_piecewise_utterance_variable_prior_alpha[:,:,:,i-1]/latent_piecewise_utterance_prior_k)), axis=2)
< 
<             self.kl_divergence_cost += self.kl_divergences_between_piecewise_prior_and_posterior*latent_variable_mask
< 
<         else:
<             self.latent_piecewise_utterance_variable_approx_posterior_alpha = theano.shared(value=numpy.float(0))
<             self.latent_piecewise_utterance_variable_prior_alpha = theano.shared(value=numpy.float(0))
< 
< 
---
>         ###
2936a1964
>         ###
2940c1968
<         # Define input vector for decoder
---
>         # Define input vector 'self.hd_input' for decoder
2943,2983c1971,1973
<             if self.add_latent_gaussian_per_utterance and self.add_latent_piecewise_per_utterance:
<                 if self.condition_decoder_only_on_latent_variable:
<                     self.hd_input = T.concatenate([self.latent_gaussian_posterior_sample, self.latent_piecewise_posterior_sample], axis=2)
<                 else:
<                     self.hd_input = T.concatenate([self.hs, self.hs_dummy, self.latent_gaussian_posterior_sample, self.latent_piecewise_posterior_sample], axis=2)
< 
<             elif self.add_latent_gaussian_per_utterance:
<                 if self.condition_decoder_only_on_latent_variable:
<                     self.hd_input = self.latent_gaussian_posterior_sample
<                 else:
<                     self.hd_input = T.concatenate([self.hs, self.hs_dummy, self.latent_gaussian_posterior_sample], axis=2)
<             elif self.add_latent_piecewise_per_utterance:
<                 if self.condition_decoder_only_on_latent_variable:
<                     self.hd_input = self.latent_piecewise_posterior_sample
<                 else:
<                     self.hd_input = T.concatenate([self.hs, self.hs_dummy, self.latent_piecewise_posterior_sample], axis=2)          
<             else:
<                 self.hd_input = T.concatenate([self.hs, self.hs_dummy], axis=2)
< 
<         else:
<             if self.add_latent_gaussian_per_utterance and self.add_latent_piecewise_per_utterance:
<                 if self.condition_decoder_only_on_latent_variable:
<                     self.hd_input =  T.concatenate([self.latent_gaussian_posterior_sample, self.latent_piecewise_posterior_sample], axis=2)
<                 else:
<                     self.hd_input = T.concatenate([self.hs, self.latent_gaussian_posterior_sample, self.latent_piecewise_posterior_sample], axis=2)
<             elif self.add_latent_gaussian_per_utterance:
<                 if self.condition_decoder_only_on_latent_variable:
<                     self.hd_input = self.latent_gaussian_posterior_sample
<                 else:
<                     self.hd_input = T.concatenate([self.hs, self.latent_gaussian_posterior_sample], axis=2)
<             elif self.add_latent_piecewise_per_utterance:
<                 if self.condition_decoder_only_on_latent_variable:
<                     self.hd_input = self.latent_piecewise_posterior_sample
<                 else:
<                     self.hd_input = T.concatenate([self.hs, self.latent_piecewise_posterior_sample], axis=2)
<             else:
<                 self.hd_input = self.hs
< 
<         # Build decoder
<         logger.debug("Build decoder (NCE)")
<         contrastive_cost, self.hd_nce, self.utterance_decoder_nce_updates = self.utterance_decoder.build_decoder(self.hd_input, training_x, y_neg=self.y_neg, y=training_y, xmask=training_hs_mask, xdropmask=training_x_dropmask, mode=UtteranceDecoder.NCE, prev_state=self.phd)
---
>             self.hd_input = T.concatenate([self.hs, self.hs_dummy], axis=2)
>         else:
>             self.hd_input = self.hs
2984a1975,1977
>         #################
>         # Build decoder #
>         #################
2986c1979,1986
<         target_probs, self.hd, target_probs_full_matrix, self.utterance_decoder_updates = self.utterance_decoder.build_decoder(self.hd_input, training_x, xmask=training_hs_mask, xdropmask=training_x_dropmask, y=training_y, mode=UtteranceDecoder.EVALUATION, prev_state=self.phd)
---
>         target_probs, self.hd, target_probs_full_matrix, self.utterance_decoder_updates =\
>             self.utterance_decoder.build_decoder(self.hd_input,
>                                                  training_x,
>                                                  xmask=training_hs_mask,
>                                                  xdropmask=training_x_dropmask,
>                                                  y=training_y,
>                                                  mode=UtteranceDecoder.EVALUATION,
>                                                  prev_state=self.phd)
2991,2992c1991,1992
<         self.debug_target_probs_full = target_probs_full_matrix
<         self.debug_returns = training_returns
---
>         self.debug_target_probs_full = target_probs_full_matrix  # full probability distribution over all words: needed for critic network
>         self.debug_returns = self.returns
2994,2995c1994,2014
<         # Prediction cost and rank cost
<         self.contrastive_cost = T.sum(contrastive_cost.flatten() * training_x_cost_mask_flat)
---
>         #############################
>         # Define the critic decoder #
>         #############################
>         critic_decoder_targets = 0.
>         if self.state['use_pg'] and not self.state['fixed_critic']:
>             assert self.enc_y_star is not None
>             assert self.enc_context is not None
>             self.critic_decoder = CriticDecoder(self.state, self.rng, self, self.dialog_encoder, self.W_emb)
>             self.q_values, self.critic_decoder_hd, self.critic_decoder_updates =\
>                 self.critic_decoder.build_decoder(self.enc_context,
>                                                   self.enc_y_star,
>                                                   self.y_sampled,
>                                                   y_sampled_mask=y_sampled_mask)
> 
>             # TODO: check target definition...! :/
>             critic_decoder_targets = self.returns + T.diagonal(T.dot(self.debug_target_probs_full, self.q_values.T))
>             # TODO: define loss and put it as a minimization objective in the training function;
> 
>         ###
>         # Define prediction cost and rank cost
>         ###
3001d2019
< 
3006,3007d2023
<         if self.use_nce:
<             self.training_cost = self.contrastive_cost
3010,3021c2026,2030
<             self.training_cost = T.sum(-T.log(target_probs) * training_returns * training_x_cost_mask_flat)
< 
<         # Compute training cost as variational lower bound with possible annealing of KL-divergence term
<         if self.add_latent_gaussian_per_utterance or self.add_latent_piecewise_per_utterance:
<             self.kl_divergence_cost_acc = T.sum(self.kl_divergence_cost)
<             if self.train_latent_variables_with_kl_divergence_annealing:
<                 assert hasattr(self, 'max_kl_percentage') == False
< 
<                 self.evaluation_cost = self.training_cost + self.kl_divergence_cost_acc
< 
<                 self.kl_divergence_cost_weight = add_to_params(self.global_params, theano.shared(value=numpy.float32(0), name='kl_divergence_cost_weight'))
<                 self.training_cost = self.training_cost + self.kl_divergence_cost_weight*self.kl_divergence_cost_acc
---
>             if not self.state['fixed_actor'] and self.state['fixed_critic']:
>                 self.training_cost = T.sum(-T.log(target_probs) * self.returns * training_x_cost_mask_flat)
>             elif not self.state['fixed_critic'] and self.state['fixed_actor']:
>                 # TODO: define training cost of critic
>                 self.training_cost = 0.
3023,3039c2032,2033
<                 if hasattr(self, 'max_kl_percentage'):
<                     self.evaluation_cost = self.training_cost + self.kl_divergence_cost_acc
< 
<                     if self.add_latent_gaussian_per_utterance:
<                         self.training_cost += T.maximum(self.max_kl_percentage*self.training_cost, T.sum(self.kl_divergences_between_gaussian_prior_and_posterior*latent_variable_mask))
< 
<                     if self.add_latent_piecewise_per_utterance:
<                         self.training_cost += T.maximum(self.max_kl_percentage*self.training_cost, T.sum(self.kl_divergences_between_piecewise_prior_and_posterior*latent_variable_mask))
< 
<                 else:
<                     self.evaluation_cost = self.training_cost + self.kl_divergence_cost_acc
<                     self.training_cost += self.kl_divergence_cost_acc
< 
<         else:
<             self.evaluation_cost = self.training_cost
<             self.kl_divergence_cost_acc = theano.shared(value=numpy.float(0))
< 
---
>                 # TODO: define training cost of critic&actor? or define 2 training costs?
>                 self.training_cost = 0.
3040a2035,2036
>         self.evaluation_cost = self.training_cost
>         self.kl_divergence_cost_acc = theano.shared(value=np.float(0))
3041a2038
>         ###
3042a2040
>         ###
3054,3088c2052
<         if self.add_latent_gaussian_per_utterance:
<             assert len(set(self.params)) + len(set(self.latent_gaussian_utterance_variable_prior_encoder.params)) \
<                 == len(set(self.params+self.latent_gaussian_utterance_variable_prior_encoder.params))
<             self.params += self.latent_gaussian_utterance_variable_prior_encoder.params
<             assert len(set(self.params)) + len(set(self.latent_gaussian_utterance_variable_approx_posterior_encoder.params)) \
<                 == len(set(self.params+self.latent_gaussian_utterance_variable_approx_posterior_encoder.params))
<             self.params += self.latent_gaussian_utterance_variable_approx_posterior_encoder.params
< 
<             assert len(set(self.params)) + len(set(self.gaussian_posterior_mean_combination.params)) \
<                 == len(set(self.params+self.gaussian_posterior_mean_combination.params))
<             self.params += self.gaussian_posterior_mean_combination.params
< 
<             assert len(set(self.params)) + len(set(self.posterior_variance_combination.params)) \
<                 == len(set(self.params+self.posterior_variance_combination.params))
<             self.params += self.posterior_variance_combination.params
< 
<             if self.condition_posterior_latent_variable_on_dcgm_encoder:
<                 assert len(set(self.params)) + len(set(self.dcgm_encoder.params)) \
<                     == len(set(self.params+self.dcgm_encoder.params))
<                 self.params += self.dcgm_encoder.params
< 
<         if self.add_latent_piecewise_per_utterance:
<             assert len(set(self.params)) + len(set(self.latent_piecewise_utterance_variable_prior_encoder.params)) \
<                 == len(set(self.params+self.latent_piecewise_utterance_variable_prior_encoder.params))
<             self.params += self.latent_piecewise_utterance_variable_prior_encoder.params
<             assert len(set(self.params)) + len(set(self.latent_piecewise_utterance_variable_approx_posterior_encoder.params)) \
<                 == len(set(self.params+self.latent_piecewise_utterance_variable_approx_posterior_encoder.params))
<             self.params += self.latent_piecewise_utterance_variable_approx_posterior_encoder.params
< 
<             if self.gate_latent_piecewise_per_utterance:
<                 assert len(set(self.params)) + len(set(self.piecewise_posterior_mean_combination.params)) \
<                     == len(set(self.params+self.piecewise_posterior_mean_combination.params))
<                 self.params += self.piecewise_posterior_mean_combination.params
< 
< 
---
>         ###
3089a2054
>         ###
3101,3106d2065
<         if self.add_latent_gaussian_per_utterance or self.add_latent_piecewise_per_utterance:
<             # We always need to exclude the KL-divergence term weight from training,
<             # since this value is being annealed (and should therefore not be optimized with SGD).
<             if self.train_latent_variables_with_kl_divergence_annealing:
<                 self.params_to_exclude += [self.kl_divergence_cost_weight]
< 
3115d2073
< 
3131,3134c2089,2090
<             if self.add_latent_gaussian_per_utterance or self.add_latent_piecewise_per_utterance:
<                 self.updates += self.latent_variable_updates
< 
<             # Add optimizer parameters to parameter set. This will ensure that they are saved and loaded correctly.
---
>             # Add optimizer parameters to parameter set.
>             # This will ensure that they are saved and loaded correctly.
3136c2092
<                 == len(set(self.params+self.optimizer_variables))
---
>                 == len(set(self.params + self.optimizer_variables))
3169,3186d2124
<             if self.add_latent_gaussian_per_utterance:
<                 self.state_updates.append((self.platent_gaussian_utterance_variable_prior, x_reset * self.latent_gaussian_utterance_variable_prior[-1]))
<                 self.state_updates.append((self.platent_gaussian_utterance_variable_approx_posterior, x_reset * self.latent_gaussian_utterance_variable_approx_posterior[-1]))
< 
<             if self.add_latent_piecewise_per_utterance:
<                 self.state_updates.append((self.platent_piecewise_utterance_variable_prior, x_reset * self.latent_piecewise_utterance_variable_prior[-1]))
<                 self.state_updates.append((self.platent_piecewise_utterance_variable_approx_posterior, x_reset * self.latent_piecewise_utterance_variable_approx_posterior[-1]))
< 
<             if self.add_latent_gaussian_per_utterance or self.add_latent_piecewise_per_utterance:
<                 if self.condition_posterior_latent_variable_on_dcgm_encoder:
<                     self.state_updates.append((self.platent_dcgm_avg, x_reset * self.latent_dcgm_avg[-1]))
<                     self.state_updates.append((self.platent_dcgm_n, x_reset.T * self.latent_dcgm_n[-1]))
< 
<                 if self.train_latent_variables_with_kl_divergence_annealing:
<                     self.state_updates.append((self.kl_divergence_cost_weight, T.minimum(1.0, self.kl_divergence_cost_weight + self.kl_divergence_annealing_rate)))
< 
< 
< 
3208d2145
< 
3216a2154
> 
