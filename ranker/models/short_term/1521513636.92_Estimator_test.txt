nangel3@jp-gpu3 ~/research/convai/ranker $ py test.py models/short_term/1521513636.92_Estimator_                                                                                            [58/1912]
/home/ml/nangel3/.local/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it wi
ll be treated as `np.float64 == np.dtype(float).type`.
from ._conv import register_converters as _register_converters

Namespace(gpu=0, short_term_model='models/short_term/1521513636.92_Estimator_')

Loading model models/short_term/1521513636.92_Estimator_ ...
prev. max train accuracies: [0.8186021, 0.8180242, 0.8238305, 0.8109521, 0.8058338, 0.81422675, 0.8281508, 0.89405614]
prev. max valid accuracies: [0.8127061, 0.8681029, 0.86568475, 0.867883, 0.86216754, 0.8681029, 0.8720598, 0.6509123]
prev. best avg. train accuracy: 0.82671
prev. best avg. valid accuracy: 0.833452
Building the networks...
WARNING:tensorflow:From /home/ml/nangel3/.local/lib/python2.7/site-packages/tensorflow/python/ops/losses/losses_impl.py:731: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) i$
deprecated and will be removed in a future version.
Instructions for updating:

Future major versions of TensorFlow will allow gradients to flow
into the labels input on backprop by default.

See tf.nn.softmax_cross_entropy_with_logits_v2.

Reset short term network parameters...
Model restored to models/short_term/1521513636.92_Estimator
Testing the short term network...
test accuracy: 0.789188
Get train, valid, test prediction...
[fold 1] train acc: 30358/36340=0.835388
[fold 1] train conf.mtrx:
[[27245  1092]
 [ 4890  3113]]
[fold 1] valid acc: 4016/4549=0.882831
[fold 1] valid conf.mtrx:
[[3748  136]
 [ 397  268]]
[fold 2] train acc: 30365/36340=0.835581
[fold 2] train conf.mtrx:
[[27265  1074]
 [ 4901  3100]]
[fold 2] valid acc: 4009/4549=0.881293
[fold 2] valid conf.mtrx:
[[3728  154]
 [ 386  281]]
[fold 3] train acc: 30309/36340=0.83404
[fold 3] train conf.mtrx:
[[27247  1097]
 [ 4934  3062]]
[fold 3] valid acc: 4065/4549=0.893603                                                                                                                                                      [11/1912]
[fold 3] valid conf.mtrx:
[[3746  131]
 [ 353  319]]
[fold 4] train acc: 30303/36340=0.833875
[fold 4] train conf.mtrx:
[[27249  1091]
 [ 4946  3054]]
[fold 4] valid acc: 4071/4549=0.894922
[fold 4] valid conf.mtrx:
[[3744  137]
 [ 341  327]]
[fold 5] train acc: 30337/36340=0.83481
[fold 5] train conf.mtrx:
[[27257  1080]
 [ 4923  3080]]
[fold 5] valid acc: 4037/4549=0.887448
[fold 5] valid conf.mtrx:
[[3736  148]
 [ 364  301]]
[fold 6] train acc: 30289/36340=0.833489
[fold 6] train conf.mtrx:
[[27231  1108]
 [ 4943  3058]]
[fold 6] valid acc: 4085/4549=0.898
[fold 6] valid conf.mtrx:
[[3762  120]
 [ 344  323]]
[fold 7] train acc: 30240/36340=0.832141
[fold 7] train conf.mtrx:
[[27214  1124]
 [ 4976  3026]]
[fold 7] valid acc: 4134/4549=0.908771
[fold 7] valid conf.mtrx:
[[3779  104]
 [ 311  355]]
[fold 8] train acc: 31413/36340=0.864419
[fold 8] train conf.mtrx:
[[28391  1035]
 [ 3892  3022]]
[fold 8] valid acc: 2961/4549=0.650912
[fold 8] valid conf.mtrx:
[[2602  193]
 [1395  359]]
avg. train acc. 0.837968
avg. train conf.mtrx.
[[27387.375  1087.625]
 [ 4800.625  3064.375]]
avg. valid acc. 0.862222
avg. valid conf.mtrx.
[[3605.625  140.375]
 [ 486.375  316.625]]
test acc: 3635/4606=0.789188
[fold 8] test conf.mtrx:
[[3395  206]
 [ 765  240]]
done.

