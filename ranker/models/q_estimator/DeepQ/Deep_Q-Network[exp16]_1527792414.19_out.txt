loading word2vec embeddings...
2018-05-31 14:46:01,161: features: INFO: loading nltk english stop words...
2018-05-31 14:46:01,169: features: INFO: set([u'all', u'just', u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'o', u'hadn', u'herself', u'll', u'had', u'should', u'to', 
u'only', u'won', u'under', u'ours', u'has', u'do', u'them', u'his', u'very', u'they', u'not', u'during', u'now', u'him', u'nor', u'd', u'did', u'didn', u'this', u'she', u'each', u'further', u'where
', u'few', u'because', u'doing', u'some', u'hasn', u'are', u'our', u'ourselves', u'out', u'what', u'for', u'while', u're', u'does', u'above', u'between', u'mustn', u't', u'be', u'we', u'who', u'wer
e', u'here', u'shouldn', u'hers', u'by', u'on', u'about', u'couldn', u'of', u'against', u's', u'isn', u'or', u'own', u'into', u'yourself', u'down', u'mightn', u'wasn', u'your', u'from', u'her', u't
heir', u'aren', u'there', u'been', u'whom', u'too', u'wouldn', u'themselves', u'weren', u'was', u'until', u'more', u'himself', u'that', u'but', u'don', u'with', u'than', u'those', u'he', u'me', u'm
yself', u'ma', u'these', u'up', u'will', u'below', u'ain', u'can', u'theirs', u'my', u'and', u've', u'then', u'is', u'am', u'it', u'doesn', u'an', u'as', u'itself', u'at', u'have', u'in', u'any', u
'if', u'again', u'no', u'when', u'same', u'how', u'other', u'which', u'you', u'shan', u'needn', u'haven', u'after', u'most', u'such', u'why', u'a', u'off', u'i', u'm', u'yours', u'so', u'y', u'the'
, u'having', u'once'])
2018-05-31 14:46:01,169: features: INFO: 
2018-05-31 14:46:01,278: extract_amt_for_q_ranker: INFO: using ALL features: ['ArticleLength', 'AverageWordEmbedding_Article', 'AverageWordEmbedding_Candidate', 'AverageWordEmbedding_LastK', 'Avera
geWordEmbedding_User', 'AverageWordEmbedding_kUser', 'BigramOverlap', 'CandidateLength', 'ConfusionWords', 'DialogActCandidate', 'DialogActLastUser', 'DialogLength', 'EntityOverlap', 'GenericTurns'
, 'IntensifierWords', 'LastUserLength', 'Negation', 'NonStopWordOverlap', 'ProfanityWords', 'SentimentScoreCandidate', 'SentimentScoreLastUser', 'Similarity_CandidateArticle', 'Similarity_Candidate
Article_noStop', 'Similarity_CandidateKUser', 'Similarity_CandidateKUser_noStop', 'Similarity_CandidateLastK', 'Similarity_CandidateLastK_noStop', 'Similarity_CandidateUser', 'TrigramOverlap', 'WhW
ords']
2018-05-31 14:46:01,283: __main__: INFO: 
2018-05-31 14:46:01,284: __main__: INFO: Namespace(article_bidir=False, article_dropout=0.4, article_hs=300, batch_size=128, context_bidir=False, context_dropout=0.4, context_hs=300, data_f='./data
/q_ranker_amt_data_1524939554.0.json', debug=False, epochs=100000, experiment=None, fix_embeddings=False, gamma=0.99, gpu=0, learning_rate=0.01, mlp_activation='prelu', mlp_dropout=0.4, mode='rnn+m
lp', model_name='DeepQ/Deep_Q-Network[exp16]', optimizer='adam', patience=20, predict_rewards=False, rnn_gate='gru', sentence_bidir=False, sentence_dropout=0.4, sentence_hs=300, update_frequence=20
00, use_custom_encs=True, utterance_bidir=False, utterance_dropout=0.4, utterance_hs=300, verbose=False, vocab_f='./data/q_ranker_amt_vocab_1524939554.0.pkl')
2018-05-31 14:46:01,284: __main__: INFO: 
2018-05-31 14:46:01,284: __main__: INFO: {'article_dropout': 0.4, 'sentence_hs': 300, 'optimizer': 'adam', 'verbose': False, 'utterance_hs': 300, 'update_frequence': 2000, 'article_hs': 300, 'learn
ing_rate': 0.01, 'use_custom_encs': True, 'batch_size': 128, 'sentence_dropout': 0.4, 'epochs': 100000, 'patience': 20, 'mlp_dropout': 0.4, 'article_bidir': False, 'utterance_dropout': 0.4, 'contex
t_hs': 300, 'predict_rewards': False, 'fix_embeddings': False, 'data_f': './data/q_ranker_amt_data_1524939554.0.json', 'context_dropout': 0.4, 'rnn_gate': 'gru', 'mlp_activation': 'prelu', 'utteran
ce_bidir': False, 'context_bidir': False, 'vocab_f': './data/q_ranker_amt_vocab_1524939554.0.pkl', 'experiment': None, 'sentence_bidir': False, 'mode': 'rnn+mlp', 'debug': False, 'gpu': 0, 'model_n
ame': 'DeepQ/Deep_Q-Network[exp16]', 'gamma': 0.99}
2018-05-31 14:46:01,284: __main__: INFO: 
2018-05-31 14:46:01,284: __main__: INFO: 
2018-05-31 14:46:01,284: __main__: INFO: Loading data from ./data/q_ranker_amt_data_1524939554.0.json...
2018-05-31 14:46:50,295: __main__: INFO: got 56564 train examples
2018-05-31 14:46:50,296: __main__: INFO: got 7114 valid examples
2018-05-31 14:46:50,296: __main__: INFO: got 7083 test examples
2018-05-31 14:46:50,297: __main__: INFO: 
2018-05-31 14:46:50,297: __main__: INFO: Loading vocabulary...
2018-05-31 14:46:50,385: __main__: INFO: number of unique tokens: 24448
2018-05-31 14:46:50,385: __main__: INFO: 
2018-05-31 14:46:50,386: __main__: INFO: Get data loaders...
2018-05-31 14:46:50,527: __main__: INFO: done.
2018-05-31 14:46:50,527: __main__: INFO: 
2018-05-31 14:46:50,527: __main__: INFO: Building word embeddings...
2018-05-31 14:46:50,742: __main__: INFO: Got 16787/24448 = 0.686641 pretrained embeddings                                                                                                  [372/1888]
2018-05-31 14:46:50,743: __main__: INFO: 
2018-05-31 14:46:50,743: __main__: INFO: Building Q-Network...
2018-05-31 14:46:54,189: __main__: INFO: DeepQNetwork(
(embed): Embedding(24448, 300)
(sentence_rnn): GRU(300, 300, batch_first=True, dropout=0.4)
(article_rnn): GRU(300, 300, batch_first=True, dropout=0.4)
(utterance_rnn): GRU(300, 300, batch_first=True, dropout=0.4)
(context_rnn): GRU(300, 300, batch_first=True, dropout=0.4)
(fc_1): Linear(in_features=600, out_features=300, bias=True)
(fc_2): Linear(in_features=300, out_features=150, bias=True)
(fc_3): Linear(in_features=150, out_features=150, bias=True)
(fc_value_1): Linear(in_features=150, out_features=75, bias=True)
(fc_value_2): Linear(in_features=75, out_features=1, bias=True)
(fc_adv_1): Linear(in_features=2029, out_features=1014, bias=True)
(fc_adv_2): Linear(in_features=1014, out_features=507, bias=True)
(fc_adv_3): Linear(in_features=507, out_features=1, bias=True)
(dropout): Dropout(p=0.4)
)
2018-05-31 14:46:54,206: __main__: INFO: 
2018-05-31 14:46:54,207: __main__: INFO: cuda available! Moving variables to cuda 0...
2018-05-31 14:46:58,839: __main__: INFO: 
2018-05-31 14:46:58,839: __main__: INFO: Training model...
2018-05-31 14:46:58,841: __main__: INFO: ***********************************
2018-05-31 14:47:02,420: __main__: INFO: iteration 0: updating target DQN.
2018-05-31 15:04:46,010: __main__: INFO: Epoch: 1 - train loss: 22.1212
2018-05-31 15:04:46,011: __main__: INFO: computing validation losses...
2018-05-31 15:06:19,100: __main__: INFO: Valid loss: 18.9373 - best valid loss: 100000
2018-05-31 15:06:23,023: __main__: INFO: Saved new model.
2018-05-31 15:06:23,027: __main__: INFO: ***********************************
2018-05-31 15:24:35,190: __main__: INFO: Epoch: 2 - train loss: 18.7772
2018-05-31 15:24:35,192: __main__: INFO: computing validation losses...
2018-05-31 15:26:07,010: __main__: INFO: Valid loss: 24.5365 - best valid loss: 18.9373
2018-05-31 15:26:07,011: __main__: INFO: No improvement. patience: 19
2018-05-31 15:26:07,012: __main__: INFO: ***********************************
2018-05-31 15:44:19,319: __main__: INFO: Epoch: 3 - train loss: 19.6144
2018-05-31 15:44:19,324: __main__: INFO: computing validation losses...
2018-05-31 15:46:02,007: __main__: INFO: Valid loss: 16.6263 - best valid loss: 18.9373
2018-05-31 15:46:05,933: __main__: INFO: Saved new model.
2018-05-31 15:46:05,933: __main__: INFO: ***********************************
2018-05-31 16:03:01,107: __main__: INFO: Epoch: 4 - train loss: 17.7651
2018-05-31 16:03:01,108: __main__: INFO: computing validation losses...
2018-05-31 16:04:22,113: __main__: INFO: Valid loss: 15.4792 - best valid loss: 16.6263
2018-05-31 16:04:26,035: __main__: INFO: Saved new model.
2018-05-31 16:04:26,035: __main__: INFO: ***********************************
2018-05-31 16:12:53,651: __main__: INFO: iteration 2000: updating target DQN.
2018-05-31 16:20:31,553: __main__: INFO: Epoch: 5 - train loss: 8.93615
2018-05-31 16:20:31,554: __main__: INFO: computing validation losses...                                                                                                                    [325/1888]
2018-05-31 16:21:41,233: __main__: INFO: Valid loss: 0.0210519 - best valid loss: 15.4792
2018-05-31 16:21:45,147: __main__: INFO: Saved new model.
2018-05-31 16:21:45,147: __main__: INFO: ***********************************
2018-05-31 16:37:36,013: __main__: INFO: Epoch: 6 - train loss: 0.0209755
2018-05-31 16:37:36,014: __main__: INFO: computing validation losses...
2018-05-31 16:38:47,990: __main__: INFO: Valid loss: 0.0205789 - best valid loss: 0.0210519
2018-05-31 16:38:51,923: __main__: INFO: Saved new model.
2018-05-31 16:38:51,925: __main__: INFO: ***********************************
2018-05-31 16:54:50,449: __main__: INFO: Epoch: 7 - train loss: 0.0203455
2018-05-31 16:54:50,450: __main__: INFO: computing validation losses...
2018-05-31 16:56:04,666: __main__: INFO: Valid loss: 0.0205677 - best valid loss: 0.0205789
2018-05-31 16:56:08,562: __main__: INFO: Saved new model.
2018-05-31 16:56:08,562: __main__: INFO: ***********************************
2018-05-31 17:11:53,380: __main__: INFO: Epoch: 8 - train loss: 0.0201502
2018-05-31 17:11:53,381: __main__: INFO: computing validation losses...
2018-05-31 17:13:05,339: __main__: INFO: Valid loss: 0.0209959 - best valid loss: 0.0205677
2018-05-31 17:13:05,340: __main__: INFO: No improvement. patience: 19
2018-05-31 17:13:05,340: __main__: INFO: ***********************************
2018-05-31 17:29:07,533: __main__: INFO: Epoch: 9 - train loss: 0.0199704
2018-05-31 17:29:07,535: __main__: INFO: computing validation losses...
2018-05-31 17:30:22,067: __main__: INFO: Valid loss: 0.0210028 - best valid loss: 0.0205677
2018-05-31 17:30:22,068: __main__: INFO: No improvement. patience: 18
2018-05-31 17:30:22,068: __main__: INFO: ***********************************
2018-05-31 17:31:20,796: __main__: INFO: iteration 4000: updating target DQN.
2018-05-31 17:45:34,890: __main__: INFO: Epoch: 10 - train loss: 0.038183
2018-05-31 17:45:34,891: __main__: INFO: computing validation losses...
2018-05-31 17:46:52,221: __main__: INFO: Valid loss: 0.0408156 - best valid loss: 0.0205677
2018-05-31 17:46:52,221: __main__: INFO: No improvement. patience: 17
2018-05-31 17:46:52,221: __main__: INFO: ***********************************
2018-05-31 18:00:22,520: __main__: INFO: Epoch: 11 - train loss: 0.0379723
2018-05-31 18:00:22,521: __main__: INFO: computing validation losses...
2018-05-31 18:01:37,936: __main__: INFO: Valid loss: 0.040176 - best valid loss: 0.0205677
2018-05-31 18:01:37,937: __main__: INFO: No improvement. patience: 16
2018-05-31 18:01:37,937: __main__: INFO: ***********************************
2018-05-31 18:15:06,235: __main__: INFO: Epoch: 12 - train loss: 0.0370007
2018-05-31 18:15:06,236: __main__: INFO: computing validation losses...
2018-05-31 18:16:28,023: __main__: INFO: Valid loss: 0.0415933 - best valid loss: 0.0205677
2018-05-31 18:16:28,024: __main__: INFO: No improvement. patience: 15
2018-05-31 18:16:28,024: __main__: INFO: ***********************************
2018-05-31 18:29:55,690: __main__: INFO: Epoch: 13 - train loss: 0.0360636
2018-05-31 18:29:55,690: __main__: INFO: computing validation losses...
2018-05-31 18:30:54,671: __main__: INFO: Valid loss: 0.040403 - best valid loss: 0.0205677
2018-05-31 18:30:54,671: __main__: INFO: No improvement. patience: 14
2018-05-31 18:30:54,672: __main__: INFO: ***********************************
2018-05-31 18:38:38,236: __main__: INFO: iteration 6000: updating target DQN.
2018-05-31 18:44:22,370: __main__: INFO: Epoch: 14 - train loss: 0.0409671
2018-05-31 18:44:22,371: __main__: INFO: computing validation losses...                                                                                                                    [278/1888]
2018-05-31 18:45:29,336: __main__: INFO: Valid loss: 0.0518824 - best valid loss: 0.0205677
2018-05-31 18:45:29,336: __main__: INFO: No improvement. patience: 13
2018-05-31 18:45:29,336: __main__: INFO: ***********************************
2018-05-31 18:58:48,943: __main__: INFO: Epoch: 15 - train loss: 0.0475822
2018-05-31 18:58:48,944: __main__: INFO: computing validation losses...
2018-05-31 18:59:58,823: __main__: INFO: Valid loss: 0.0505408 - best valid loss: 0.0205677
2018-05-31 18:59:58,823: __main__: INFO: No improvement. patience: 12
2018-05-31 18:59:58,823: __main__: INFO: ***********************************
2018-05-31 19:13:22,490: __main__: INFO: Epoch: 16 - train loss: 0.0462297
2018-05-31 19:13:22,491: __main__: INFO: computing validation losses...
2018-05-31 19:14:32,048: __main__: INFO: Valid loss: 0.0512168 - best valid loss: 0.0205677
2018-05-31 19:14:32,049: __main__: INFO: No improvement. patience: 11
2018-05-31 19:14:32,049: __main__: INFO: ***********************************
2018-05-31 19:27:53,583: __main__: INFO: Epoch: 17 - train loss: 0.0457084
2018-05-31 19:27:53,583: __main__: INFO: computing validation losses...
2018-05-31 19:29:09,670: __main__: INFO: Valid loss: 0.0516601 - best valid loss: 0.0205677
2018-05-31 19:29:09,670: __main__: INFO: No improvement. patience: 10
2018-05-31 19:29:09,670: __main__: INFO: ***********************************
2018-05-31 19:42:25,817: __main__: INFO: Epoch: 18 - train loss: 0.0444408
2018-05-31 19:42:25,818: __main__: INFO: computing validation losses...
2018-05-31 19:43:36,551: __main__: INFO: Valid loss: 0.0527349 - best valid loss: 0.0205677
2018-05-31 19:43:36,552: __main__: INFO: No improvement. patience: 9
2018-05-31 19:43:36,552: __main__: INFO: ***********************************
2018-05-31 19:44:52,923: __main__: INFO: iteration 8000: updating target DQN.
2018-05-31 19:56:51,169: __main__: INFO: Epoch: 19 - train loss: 0.0475048
2018-05-31 19:56:51,170: __main__: INFO: computing validation losses...
2018-05-31 19:58:06,300: __main__: INFO: Valid loss: 0.0564533 - best valid loss: 0.0205677
2018-05-31 19:58:06,300: __main__: INFO: No improvement. patience: 8
2018-05-31 19:58:06,300: __main__: INFO: ***********************************
2018-05-31 20:11:29,433: __main__: INFO: Epoch: 20 - train loss: 0.0464904
2018-05-31 20:11:29,433: __main__: INFO: computing validation losses...
2018-05-31 20:12:39,204: __main__: INFO: Valid loss: 0.0548767 - best valid loss: 0.0205677
2018-05-31 20:12:39,205: __main__: INFO: No improvement. patience: 7
2018-05-31 20:12:39,205: __main__: INFO: ***********************************
2018-05-31 20:26:07,248: __main__: INFO: Epoch: 21 - train loss: 345.816
2018-05-31 20:26:07,249: __main__: INFO: computing validation losses...
2018-05-31 20:27:11,605: __main__: INFO: Valid loss: 0.0502155 - best valid loss: 0.0205677
2018-05-31 20:27:11,605: __main__: INFO: No improvement. patience: 6
2018-05-31 20:27:11,605: __main__: INFO: ***********************************
2018-05-31 20:40:38,016: __main__: INFO: Epoch: 22 - train loss: 0.0450221
2018-05-31 20:40:38,017: __main__: INFO: computing validation losses...
2018-05-31 20:41:48,665: __main__: INFO: Valid loss: 0.0534936 - best valid loss: 0.0205677
2018-05-31 20:41:48,666: __main__: INFO: No improvement. patience: 5
2018-05-31 20:41:48,666: __main__: INFO: ***********************************
2018-05-31 20:50:09,419: __main__: INFO: iteration 10000: updating target DQN.
2018-05-31 20:55:06,804: __main__: INFO: Epoch: 23 - train loss: 0.0441595
2018-05-31 20:55:06,805: __main__: INFO: computing validation losses...
2018-05-31 20:56:16,223: __main__: INFO: Valid loss: 0.049911 - best valid loss: 0.0205677
2018-05-31 20:56:16,224: __main__: INFO: No improvement. patience: 4
2018-05-31 20:56:16,224: __main__: INFO: ***********************************
2018-05-31 21:09:36,790: __main__: INFO: Epoch: 24 - train loss: 0.0426188
2018-05-31 21:09:36,791: __main__: INFO: computing validation losses...
2018-05-31 21:10:47,874: __main__: INFO: Valid loss: 0.0482026 - best valid loss: 0.0205677
2018-05-31 21:10:47,874: __main__: INFO: No improvement. patience: 3
2018-05-31 21:10:47,875: __main__: INFO: ***********************************
2018-05-31 21:24:03,821: __main__: INFO: Epoch: 25 - train loss: 0.0424583
2018-05-31 21:24:03,822: __main__: INFO: computing validation losses...
2018-05-31 21:25:02,936: __main__: INFO: Valid loss: 0.0497078 - best valid loss: 0.0205677
2018-05-31 21:25:02,937: __main__: INFO: No improvement. patience: 2
2018-05-31 21:25:02,937: __main__: INFO: ***********************************
2018-05-31 21:38:13,671: __main__: INFO: Epoch: 26 - train loss: 0.0427435
2018-05-31 21:38:13,672: __main__: INFO: computing validation losses...
2018-05-31 21:39:30,007: __main__: INFO: Valid loss: 0.0483168 - best valid loss: 0.0205677
2018-05-31 21:39:30,007: __main__: INFO: No improvement. patience: 1
2018-05-31 21:39:30,007: __main__: INFO: ***********************************
2018-05-31 21:52:46,464: __main__: INFO: Epoch: 27 - train loss: 0.0431672
2018-05-31 21:52:46,465: __main__: INFO: computing validation losses...
2018-05-31 21:53:56,531: __main__: INFO: Valid loss: 0.0437349 - best valid loss: 0.0205677
2018-05-31 21:53:56,532: __main__: INFO: No improvement. patience: 0
2018-05-31 21:53:56,535: __main__: INFO: Finished training. Time elapsed: 25617.7 seconds
2018-05-31 21:53:56,535: __main__: INFO: Saving timings...
2018-05-31 21:53:56,539: __main__: INFO: done.
