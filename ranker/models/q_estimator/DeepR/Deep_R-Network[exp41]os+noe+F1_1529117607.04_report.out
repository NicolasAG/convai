[nangel3][agent-server-2][~/research/convai/ranker] py q_test.py models/q_estimator/DeepR/Deep_R-Network\[exp41\]os+noe+F1_1529117607.04 --gpu 0                                           [114/1955]
loading word2vec embeddings...
2018-07-28 12:24:24,132: features: INFO: loading nltk english stop words...
2018-07-28 12:24:24,147: features: INFO: set([u'all', u'just', u'being', u'over', u'both', u'through', u'yourselves', u'its', u'before', u'o', u'hadn', u'herself', u'll', u'had', u'should', u'to', 
u'only', u'won', u'under', u'ours', u'has', u'do', u'them', u'his', u'very', u'they', u'not', u'during', u'now', u'him', u'nor', u'd', u'did', u'didn', u'this', u'she', u'each', u'further', u'where
', u'few', u'because', u'doing', u'some', u'hasn', u'are', u'our', u'ourselves', u'out', u'what', u'for', u'while', u're', u'does', u'above', u'between', u'mustn', u't', u'be', u'we', u'who', u'wer
e', u'here', u'shouldn', u'hers', u'by', u'on', u'about', u'couldn', u'of', u'against', u's', u'isn', u'or', u'own', u'into', u'yourself', u'down', u'mightn', u'wasn', u'your', u'from', u'her', u't
heir', u'aren', u'there', u'been', u'whom', u'too', u'wouldn', u'themselves', u'weren', u'was', u'until', u'more', u'himself', u'that', u'but', u'don', u'with', u'than', u'those', u'he', u'me', u'm
yself', u'ma', u'these', u'up', u'will', u'below', u'ain', u'can', u'theirs', u'my', u'and', u've', u'then', u'is', u'am', u'it', u'doesn', u'an', u'as', u'itself', u'at', u'have', u'in', u'any', u
'if', u'again', u'no', u'when', u'same', u'how', u'other', u'which', u'you', u'shan', u'needn', u'haven', u'after', u'most', u'such', u'why', u'a', u'off', u'i', u'm', u'yours', u'so', u'y', u'the'
, u'having', u'once'])
2018-07-28 12:24:24,147: features: INFO: 
2018-07-28 12:24:24,312: extract_amt_for_q_ranker: INFO: using ALL features: ['ArticleLength', 'AverageWordEmbedding_Article', 'AverageWordEmbedding_Candidate', 'AverageWordEmbedding_LastK', 'Avera
geWordEmbedding_User', 'AverageWordEmbedding_kUser', 'BigramOverlap', 'CandidateLength', 'ConfusionWords', 'DialogActCandidate', 'DialogActLastUser', 'DialogLength', 'EntityOverlap', 'GenericTurns'
, 'IntensifierWords', 'LastUserLength', 'Negation', 'NonStopWordOverlap', 'ProfanityWords', 'SentimentScoreCandidate', 'SentimentScoreLastUser', 'Similarity_CandidateArticle', 'Similarity_Candidate
Article_noStop', 'Similarity_CandidateKUser', 'Similarity_CandidateKUser_noStop', 'Similarity_CandidateLastK', 'Similarity_CandidateLastK_noStop', 'Similarity_CandidateUser', 'TrigramOverlap', 'WhW
ords']
2018-07-28 12:24:29,377: __main__: INFO: 
2018-07-28 12:24:29,377: __main__: INFO: Namespace(gpu=0, model_prefix='models/q_estimator/DeepR/Deep_R-Network[exp41]os+noe+F1_1529117607.04', verbose=False)
2018-07-28 12:24:29,378: __main__: INFO: 
2018-07-28 12:24:29,381: __main__: INFO: old parameters: {u'sentence_hs': 300, u'verbose': False, u'article_bidir': False, u'utterance_hs': 300, u'update_frequence': 2000, u'article_hs': 300, u'epo
chs': 100000, u'patience': 20, u'mlp_dropout': 0.4, u'context_dropout': 0.4, u'utterance_dropout': 0.4, u'fix_embeddings': False, u'data_f': u'./data/q_ranker_amt_data++_1525301962.86.json', u'expe
riment': None, u'sentence_bidir': False, u'gpu': 1, u'article_dropout': 0.4, u'optimizer': u'sgd', u'learning_rate': 0.001, u'use_custom_encs': False, u'batch_size': 128, u'sentence_dropout': 0.4, 
u'context_hs': 300, u'predict_rewards': True, u'rnn_gate': u'gru', u'mlp_activation': u'prelu', u'utterance_bidir': False, u'model_name': u'DeepR/Deep_R-Network[exp41]os+noe+F1', u'vocab_f': u'./da
ta/q_ranker_amt_vocab_1525301962.86.pkl', u'mode': u'rnn+mlp', u'debug': False, u'context_bidir': False, u'gamma': 0.99}
2018-07-28 12:24:29,383: __main__: INFO: 
2018-07-28 12:24:29,383: __main__: INFO: Loading data from ./data/q_ranker_amt_data_1527760664.38.pkl...
2018-07-28 12:30:02,243: __main__: INFO: got 7083 test examples
2018-07-28 12:30:02,243: __main__: INFO: 
2018-07-28 12:30:02,243: __main__: INFO: Loading vocabulary...
2018-07-28 12:30:02,335: __main__: INFO: number of unique tokens: 24448
2018-07-28 12:30:02,335: __main__: INFO: 
2018-07-28 12:30:02,335: __main__: INFO: Get data loaders...
2018-07-28 12:30:02,377: __main__: INFO: done.
2018-07-28 12:30:02,377: __main__: INFO: 
2018-07-28 12:30:02,377: __main__: INFO: Building word embeddings...
2018-07-28 12:30:02,689: __main__: INFO: Got 16787/24448 = 0.686641 pretrained embeddings
2018-07-28 12:30:02,689: __main__: INFO: 
2018-07-28 12:30:02,689: __main__: INFO: Building Q-Network...
2018-07-28 12:30:13,371: __main__: INFO: DeepQNetwork(
(embed): Embedding(24448, 300)
(sentence_rnn): GRU(300, 300, batch_first=True, dropout=0.4)
(article_rnn): GRU(300, 300, batch_first=True, dropout=0.4)
(utterance_rnn): GRU(300, 300, batch_first=True, dropout=0.4)
(context_rnn): GRU(300, 300, batch_first=True, dropout=0.4)
(fc_1): Linear(in_features=600, out_features=300, bias=True)
(fc_2): Linear(in_features=300, out_features=150, bias=True)
(fc_3): Linear(in_features=150, out_features=150, bias=True)
(fc_value_1): Linear(in_features=150, out_features=75, bias=True)
(fc_value_2): Linear(in_features=75, out_features=2, bias=True)
(fc_adv_1): Linear(in_features=450, out_features=225, bias=True)
(fc_adv_2): Linear(in_features=225, out_features=112, bias=True)
(fc_adv_3): Linear(in_features=112, out_features=2, bias=True)
(dropout): Dropout(p=0.4)
)
2018-07-28 12:30:13,372: __main__: INFO: 
2018-07-28 12:30:13,372: __main__: INFO: cuda available! Moving variables to cuda 0...
2018-07-28 12:30:14,549: __main__: INFO: 
2018-07-28 12:30:14,549: __main__: INFO: Plotting timings...
2018-07-28 12:30:14,857: __main__: INFO: best valid loss: 0.533104 achieved at epoch 54
2018-07-28 12:30:14,857: __main__: INFO: training loss at this epoch: 0.433779
2018-07-28 12:30:15,115: __main__: INFO: best valid acc: 0.770858 achieved at epoch 66
2018-07-28 12:30:15,115: __main__: INFO: training acc at this epoch: 0.868131
2018-07-28 12:30:15,367: __main__: INFO: best valid f1: 0.373126 achieved at epoch 54
2018-07-28 12:30:15,368: __main__: INFO: training f1 at this epoch: 0.803719
2018-07-28 12:30:15,368: __main__: INFO: done.
2018-07-28 12:30:15,368: __main__: INFO: 
2018-07-28 12:30:15,368: __main__: INFO: Testing model in batches...
2018-07-28 12:31:32,348: __main__: INFO: Test loss: 0.497132 - test accuracy:
{
"acc": 0.7662122352574751, 
"F1": 0.3793268145990591, 
"FDR": 0.6885844148727174, 
"FOR": 0.09556188842049661, 
"TPR": 0.49233070421150915, 
"FPR": 0.18747213867626716, 
"TNR": 0.8125278613237332, 
"NPV": 0.9044381115795032, 
"FNR": 0.5076692957884908, 
"PPV": 0.31141558512728273
}
2018-07-28 12:31:32,349: __main__: INFO: Finished testing. Time elapsed: 76.981 seconds
2018-07-28 12:31:32,349: __main__: INFO: 
2018-07-28 12:31:32,349: __main__: INFO: Testing model one example at a time & generating report.json
2018-07-28 12:34:05,683: __main__: INFO: Now simulating the old chatbot decision policy...
2018-07-28 12:34:10,894: __main__: INFO: Finished 1-by-1 testing. Time elapsed: 158.545 seconds
2018-07-28 12:34:10,894: __main__: INFO: 
2018-07-28 12:34:10,894: __main__: INFO: Saving report...
2018-07-28 12:34:11,343: __main__: INFO: done.
2018-07-28 12:34:11,344: __main__: INFO: 
2018-07-28 12:34:11,344: __main__: INFO: Measuring recall at predicting best candidate...
2018-07-28 12:34:11,933: __main__: INFO: Predicted like human behavior with rulebased selection:
2018-07-28 12:34:11,933: __main__: INFO: - recall@1: 382 / 1028 = 0.371595
2018-07-28 12:34:11,933: __main__: INFO: - recall@2: 578 / 1028 = 0.562257
2018-07-28 12:34:11,933: __main__: INFO: - recall@3: 704 / 1028 = 0.684825
2018-07-28 12:34:11,934: __main__: INFO: - recall@4: 785 / 1028 = 0.763619
2018-07-28 12:34:11,934: __main__: INFO: - recall@5: 851 / 1028 = 0.827821
2018-07-28 12:34:11,934: __main__: INFO: - recall@6: 902 / 1028 = 0.877432
2018-07-28 12:34:11,934: __main__: INFO: - recall@7: 947 / 1028 = 0.921206
2018-07-28 12:34:11,934: __main__: INFO: - recall@8: 1028 / 1028 = 1
2018-07-28 12:34:11,934: __main__: INFO: - recall@9: 1028 / 1028 = 1
2018-07-28 12:34:11,934: __main__: INFO: Predicted like human behavior with argmax selection:
2018-07-28 12:34:11,934: __main__: INFO: - recall@1: 383 / 1028 = 0.372568
2018-07-28 12:34:11,934: __main__: INFO: - recall@2: 608 / 1028 = 0.59144
2018-07-28 12:34:11,934: __main__: INFO: - recall@3: 726 / 1028 = 0.706226
2018-07-28 12:34:11,934: __main__: INFO: - recall@4: 824 / 1028 = 0.801556
2018-07-28 12:34:11,934: __main__: INFO: - recall@5: 906 / 1028 = 0.881323
2018-07-28 12:34:11,934: __main__: INFO: - recall@6: 964 / 1028 = 0.937743
2018-07-28 12:34:11,934: __main__: INFO: - recall@7: 1007 / 1028 = 0.979572
2018-07-28 12:34:11,934: __main__: INFO: - recall@8: 1028 / 1028 = 1
2018-07-28 12:34:11,934: __main__: INFO: - recall@9: 1028 / 1028 = 1
2018-07-28 12:34:11,934: __main__: INFO: Predicted like human behavior with sampled selection:
2018-07-28 12:34:11,934: __main__: INFO: - recall@1: 215 / 1028 = 0.209144
2018-07-28 12:34:11,935: __main__: INFO: - recall@2: 421 / 1028 = 0.409533
2018-07-28 12:34:11,935: __main__: INFO: - recall@3: 551 / 1028 = 0.535992
2018-07-28 12:34:11,935: __main__: INFO: - recall@4: 661 / 1028 = 0.642996
2018-07-28 12:34:11,935: __main__: INFO: - recall@5: 745 / 1028 = 0.724708
2018-07-28 12:34:11,935: __main__: INFO: - recall@6: 857 / 1028 = 0.833658
2018-07-28 12:34:11,935: __main__: INFO: - recall@7: 950 / 1028 = 0.924125
2018-07-28 12:34:11,935: __main__: INFO: - recall@8: 1028 / 1028 = 1
2018-07-28 12:34:11,935: __main__: INFO: - recall@9: 1028 / 1028 = 1
2018-07-28 12:34:12,168: __main__: INFO: 
2018-07-28 12:34:12,168: __main__: INFO: Measuring recall@1 for each context length...
2018-07-28 12:34:12,468: __main__: INFO: Predicted like human behavior with rulebased selection:
2018-07-28 12:34:12,468: __main__: INFO: - recall@1 for context of size 1: 92 / 177 = 0.519774011299
2018-07-28 12:34:12,468: __main__: INFO: - recall@1 for context of size 3: 53 / 177 = 0.299435028249
2018-07-28 12:34:12,468: __main__: INFO: - recall@1 for context of size 5: 53 / 177 = 0.299435028249
2018-07-28 12:34:12,468: __main__: INFO: - recall@1 for context of size 7: 58 / 177 = 0.327683615819
2018-07-28 12:34:12,468: __main__: INFO: - recall@1 for context of size 9: 58 / 177 = 0.327683615819
2018-07-28 12:34:12,468: __main__: INFO: - recall@1 for context of size 11: 35 / 75 = 0.466666666667
2018-07-28 12:34:12,468: __main__: INFO: - recall@1 for context of size 13: 16 / 28 = 0.571428571429
2018-07-28 12:34:12,468: __main__: INFO: - recall@1 for context of size 15: 6 / 17 = 0.352941176471
2018-07-28 12:34:12,468: __main__: INFO: - recall@1 for context of size 17: 4 / 12 = 0.333333333333
2018-07-28 12:34:12,468: __main__: INFO: - recall@1 for context of size 19: 6 / 7 = 0.857142857143
2018-07-28 12:34:12,468: __main__: INFO: - recall@1 for context of size 21: 1 / 4 = 0.25
2018-07-28 12:34:12,468: __main__: INFO: Predicted like human behavior with argmax selection:
2018-07-28 12:34:12,468: __main__: INFO: - recall@1 for context of size 1: 110 / 177 = 0.621468926554
2018-07-28 12:34:12,468: __main__: INFO: - recall@1 for context of size 3: 54 / 177 = 0.305084745763
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 5: 54 / 177 = 0.305084745763
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 7: 51 / 177 = 0.28813559322
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 9: 55 / 177 = 0.310734463277
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 11: 31 / 75 = 0.413333333333
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 13: 13 / 28 = 0.464285714286
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 15: 6 / 17 = 0.352941176471
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 17: 4 / 12 = 0.333333333333
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 19: 3 / 7 = 0.428571428571
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 21: 2 / 4 = 0.5
2018-07-28 12:34:12,469: __main__: INFO: Predicted like human behavior with sampled selection:
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 1: 98 / 177 = 0.553672316384
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 3: 26 / 177 = 0.146892655367
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 5: 35 / 177 = 0.197740112994
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 7: 31 / 177 = 0.175141242938
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 9: 18 / 177 = 0.101694915254
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 11: 10 / 75 = 0.133333333333
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 13: 3 / 28 = 0.107142857143
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 15: 2 / 17 = 0.117647058824
2018-07-28 12:34:12,469: __main__: INFO: - recall@1 for context of size 17: 1 / 12 = 0.0833333333333
2018-07-28 12:34:12,470: __main__: INFO: - recall@1 for context of size 19: 1 / 7 = 0.142857142857
2018-07-28 12:34:12,470: __main__: INFO: - recall@1 for context of size 21: 0 / 4 = 0.0
2018-07-28 12:34:12,728: __main__: INFO: done.
