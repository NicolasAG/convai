#!/bin/bash

# download the data files here, and install any dependencies
location_base="http://132.206.3.23:8030/"
hred_twitter_model="twitter_model.zip"
hred_reddit_model="reddit_model.zip"
de_reddit_model="reddit-bpe5k_exp2.zip"
de_reddit_data="DE.zip"
followup_data="followup.zip"

echo "-------Downloading models-----------"
wget "$location_base$hred_twitter_model"
unzip "$hred_twitter_model"

wget "$location_base$hred_reddit_model"
unzip "$hred_reddit_model"

wget "$location_base$de_reddit_model"
unzip "$de_reddit_model"

wget "$location_base$de_reddit_data"
unzip "$de_reddit_data"

wget "$location_base$followup_data"
unzip "$followup_data"

echo "-------Models downloaded-----------"



echo "-------Downloading Word2Vec--------"

OUTPUT=$( wget --save-cookies cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=0B7XkCwpI5KDYNlNUTTlSS21pQmM' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/Code: \1\n/p' )
CODE=${OUTPUT##*Code: }
echo "code: $CODE"
F='GoogleNews-vectors-negative300.bin.gz'
if [ -z "$1" ]
    then
        OUT_F=$F
    else
        OUT_F=$1/$F
fi
echo "out_f: $OUT_F"
wget --load-cookies cookies.txt 'https://docs.google.com/uc?export=download&confirm='$CODE'&id=0B7XkCwpI5KDYNlNUTTlSS21pQmM' -O $OUT_F
echo "Unziping Word2Vec file..."
gunzip $OUT_F

echo "-------Word2Vec downloaded--------"



echo "-------Downloading nltk corpora-------"
python -c "import nltk; nltk.download('stopwords')"
echo "-------nltk corpora downloaded--------"



