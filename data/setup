#!/bin/bash

# download the data files here, and install any dependencies
location_base="http://132.206.3.23:8030/"
hred_twitter_model="twitter_model.zip"
hred_reddit_model="reddit_model.zip"
de_reddit_model="reddit-bpe5k_exp2.zip"
de_reddit_data="DE.zip"
followup_data="followup.zip"

echo "-------Downloading models-----------"
wget "$location_base$hred_twitter_model"
unzip "$hred_twitter_model"

wget "$location_base$hred_reddit_model"
unzip "$hred_reddit_model"

wget "$location_base$de_reddit_model"
unzip "$de_reddit_model"

wget "$location_base$de_reddit_data"
unzip "$de_reddit_data"

wget "$location_base$followup_data"
unzip "$followup_data"

# Stuff for DrQA
GLOVE_DIR=glove
mkdir -p $GLOVE_DIR
wget http://nlp.stanford.edu/data/glove.840B.300d.zip -O $GLOVE_DIR/glove.840B.300d.zip
unzip $GLOVE_DIR/glove.840B.300d.zip -d $GLOVE_DIR

wget https://s3.amazonaws.com/fair-data/parlai/_models/drqa/squad.mdl

# Download SpaCy English language models
python3 -m spacy download en


echo "-------Models downloaded-----------"
